{"config":{"lang":["fr"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Bienvenu sur la formation Deep Learning du CITC","title":"Home"},{"location":"#bienvenu-sur-la-formation-deep-learning-du-citc","text":"","title":"Bienvenu sur la formation Deep Learning du CITC"},{"location":"test/","text":"Module 1 : Introduction au deep learning, prise en main de Tensorflow et Keras Pr\u00e9liminaires, notations et conventions Dans la suite de ces modules, on se place de le cadre d'un apprentissage dit supervis\u00e9 , on consid\u00e9rera donc la probl\u00e9matique suivante : Probl\u00e9matique On note \\(\\mathbf{R}^{j}\\) l'espace vectoriel r\u00e9el de dimension \\(j\\) . Etant donn\u00e9 le dataset (fini) suivant. \\[ \\mathcal{X} = \\lbrace (\\mathbf{x}_{i}, \\mathbf{y}_{i})\\rbrace_{i \\in I} \\quad (\\mathbf{x}_{i}, \\mathbf{y}_{i}) \\in \\mathbf{R}^{m} \\times \\mathbf{R}^{k} \\] On suppose que \\(\\mathbf{x}_{i}\\) et \\(\\mathbf{y}_{i}\\) sont reli\u00e9s entre eux par une fonction inconnue \\(f : \\mathbf{R}^{m} \\rightarrow \\mathbf{R}^{k}\\) v\u00e9rifiant la relation suivante. \\[ f(\\mathbf{x}_{i}) = \\mathbf{y}_{i} + \\varepsilon \\] D\u00e9terminer un algorithme estimant \\(f\\) , c'est \u00e0 dire produisant une fonction \\[ \\hat{f} : \\mathbf{R}^{m} \\rightarrow \\mathbf{R}^{k} \\] telle que \\(\\hat{f}(\\mathbf{x}_{i}) = \\hat{\\mathbf{y}}_{i}\\) avec \\(\\hat{\\mathbf{y}}_{i} \\simeq \\mathbf{y}_{i}\\) . Pour d\u00e9terminer \\(\\hat{f}\\) , on se place alors dans le cadre des r\u00e9seaux de neurones. On utilisera les conventions suivantes. \\(I = \\lbrace 1, \\dots, n \\rbrace\\) est un ensemble discret fini, \\(|I| = n\\) est le nombre d' observations dans le dataset. Le couple \\((\\mathbf{x}_{i}, \\mathbf{y}_{i})\\) est alors appel\u00e9 la \\(i\\) -i\u00e8me observation du dataset. \\(\\mathbf{x}_{i} = (x_{i,1}, \\dots, x_{i,m}) \\in \\mathbf{R}^{m}\\) est l'ensemble des features (caract\u00e9ristiques) de la \\(i\\) -i\u00e8me observation du dataset et \\(\\mathbf{y}_{i} = (y_{i,1}, \\dots, y_{i,k}) \\in \\mathbf{R}^{k}\\) est la cible de la \\(i\\) -i\u00e8me observation du dataset. La fonction \\(\\hat{f}\\) est un mod\u00e8le de \\(f\\) , et \\(\\hat{f}(\\mathbf{x}_{i}) = \\hat{\\mathbf{y}}_{i}\\) est une pr\u00e9diction . Le commencement du d\u00e9but : les neurosciences & le fonctionnement d'un neurone biologique Avant de parler des neurones artificiels, jetons un coup d'\u0153il rapide sur un neurone biologique. Il s'agit d'une cellule d'apparence inhabituelle que l'on trouve surtout dans les cerveaux d'animaux. Elle est compos\u00e9e d'un corps cellulaire contenant le noyau et la plupart des \u00e9l\u00e9ments du complexe cellulaire, de nombreuses extensions de ramification appel\u00e9es dendrites , plus une tr\u00e8s longue extension appel\u00e9e l' axone . La longueur de l'axone peut \u00eatre juste quelques fois plus longue que la cellule, ou jusqu'\u00e0 des dizaines de milliers de fois plus. Pr\u00e8s de son extr\u00e9mit\u00e9, l'axone se d\u00e9tache en de nombreuses branches appel\u00e9es t\u00e9lodendries , et \u00e0 l'extr\u00e9mit\u00e9 de ces branches se trouvent de minuscules structures appel\u00e9es bornes synaptiques (ou simplement synapses ), qui sont connect\u00e9es \u00e0 la dendrite ou aux corps d'autres neurones. Les neurones biologiques produisent de courtes impulsions \u00e9lectrique appel\u00e9es potentiels d'action (PA, ou simplement des signaux) qui se d\u00e9placent le long des axones et font en sorte que les synapses \u00e9mettent des signaux chimiques appel\u00e9s neurotransmetteurs. Quand un neurone re\u00e7oit une quantit\u00e9 suffisante de ces neurotransmetteurs en quelques millisecondes, il envoie ses propres impulsions \u00e9lectriques (en fait, cela d\u00e9pend des neurotransmetteurs, car certains d'entre eux emp\u00eachent le neurone de s'activer). Ainsi, les neurones biologiques individuels semblent se comporter de mani\u00e8re assez simple, mais ils sont organis\u00e9s en un vaste r\u00e9seau de plusieurs milliards , chaque neurone \u00e9tant g\u00e9n\u00e9ralement connect\u00e9 \u00e0 des milliers d'autres neurones. Des calculs tr\u00e8s complexes peuvent \u00eatre effectu\u00e9s par un r\u00e9seau de neurones assez simples, de la m\u00eame fa\u00e7on que d'une fourmili\u00e8re peut \u00e9merger les efforts combin\u00e9s de simples fourmis. L'architecture des r\u00e9seaux neuronaux biologiques (BNN) fait toujours l'objet de recherches actives, mais certaines parties du cerveau ont \u00e9t\u00e9 cartographi\u00e9es et il semble que les neurones sont souvent organis\u00e9s en couches cons\u00e9cutives, sp\u00e9cialement dans le cortex c\u00e9r\u00e9bral (la couche externe de votre cerveau). Le neurone de McCulloch-Pitts et le perceptron L'id\u00e9e premi\u00e8re de laquelle d\u00e9coule l'invention des neurones artificiels est la volont\u00e9e d'avoir un algorithme de classification binaire. Le neurone de McCulloch-Pitts Le premier article scientifique mod\u00e9lisant de fa\u00e7on math\u00e9matique un neurone biologique a \u00e9t\u00e9 r\u00e9dig\u00e9 en 1943 par le neurobiologiste Warren McCulloch et le math\u00e9maticien Walter Pitts . Le neurone de McCulloch-Pitts est simple : Le neurone correspond \u00e0 une fonction ayant une ou plusieurs entr\u00e9e binaires et une sortie binaire (0 ou 1). Le neurone ne s'active (produit une sortie) que si le nombre d'entr\u00e9e active d\u00e9passe un certain seuil. On rappelle que la fonction de Heaviside \\(H\\) est d\u00e9finie par : \\[ \\begin{array}{ccccc} H & : & \\mathbf{R} & \\to & [0,1] \\\\ & & x & \\mapsto & H(x) \\\\ \\end{array} \\] avec \\[ H(x) = \\begin{cases} 1 & x \\geq 0, \\\\ 0 & x < 0.\\end{cases} \\] Remarque Un neurone de McCulloch-Pitts est donn\u00e9 par : des entr\u00e9es binaires \\((x_{1}, \\dots, x_{m})\\) , un r\u00e9el \\(\\vartheta \\in \\mathbf{R}\\) , une sortie \\(\\hat{y}\\) , d\u00e9finie par l'\u00e9quation suivante. \\[ \\hat{y} = H(\\sum_{i=1}^{m} x_{i} - \\vartheta), \\quad \\forall i \\in I, x_{i} \\in \\lbrace 0,1 \\rbrace \\] o\u00f9 \\(H\\) est la fonction de Heaviside, et \\(\\vartheta\\) est le seuil. On dit que le neurone s'active si \\(\\sum_{i=1}^{m} x_{i} - \\vartheta > 0\\) . Le neurone tel que d\u00e9fini par McCulloch et Pitts est consid\u00e9r\u00e9 comme une simple porte logique : il n'y a pas d'algorithme associ\u00e9 afin de l'entra\u00eener. Ils montr\u00e8rent cependant qu'un r\u00e9seau constitu\u00e9 des neurones formels de leur invention a la m\u00eame puissance de calcul qu'une machine de Turing, ie ce r\u00e9seau est capable de calculer toutes les propositions logiques. Exemple Mod\u00e9lisons les portes logiques ET et OU via les neurones de McCulloch-Pitts. Quelle valeur de \\(\\vartheta\\) prendre ? D\u00e9finition La fonction brisant la lin\u00e9arit\u00e9 \u00e0 la sortie du neurone, dans notre cas pour l'instant la fonction de Heaviside \\(H\\) , sera appel\u00e9e fonction d'activation du neurone. Attention Le neurone de McCulloch Pitts poss\u00e8de les limites suivantes : Impossibilit\u00e9 de fournir des entr\u00e9es non bool\u00e9ennes. Le seuil doit toujours \u00eatre d\u00e9fini manuellement. Toutes les entr\u00e9es sont \u00e9galement importante, on ne peut pas assigner une importance plus grande \u00e0 certaines entr\u00e9es. Le Perceptron En 1958, puis 1962, Frank Rosenblatt g\u00e9n\u00e9ralise les travaux de McCulloch et Pitts en d\u00e9veloppant le Perceptron . Le Perceptron de Rosenblatt est essentiellement un neurone de McCulloch-Pitts, o\u00f9 les entr\u00e9es \\((x_{1}, \\dots, x_{m})\\) peuvent cette fois ci prendre des valeurs r\u00e9elles. De plus, chaque entr\u00e9e est maintenant pond\u00e9r\u00e9e, le poids \\(w_{i}\\) \u00e9tant lui aussi \u00e0 valeur r\u00e9elle. Un poids positif ( \\(w_{i} > 0\\) ) refl\u00e9tant une synapse excitatrice, tandis qu'un poids n\u00e9gatif ( \\(w_{i} < 0\\) ) repr\u00e9sente lui une synapse inhibitrice. D\u00e9finition Un Perceptron est donn\u00e9 par : des entr\u00e9es \\((x_{1}, \\dots, x_{m}) \\in \\mathbf{R}^{m}\\) , des poids \\((w_{1}, \\dots, w_{m}) \\in \\mathbf{R}^{m}\\) , un r\u00e9el \\(\\vartheta \\in \\mathbf{R}\\) , une sortie \\(\\hat{y}\\) , d\u00e9finie par l'\u00e9quation suivante. \\[ \\hat{y} = H(\\sum_{i=1}^{m} w_{i}x_{i} - \\vartheta), \\forall i \\in I, (w_{i}, x_{i}) \\in \\mathbf{R}^{2} \\] o\u00f9 \\(H\\) est la fonction de Heavyside, et \\(\\vartheta\\) est le seuil. On dit que le neurone s'active si \\(\\sum_{i=1}^{m} w_{i}x_{i} - \\vartheta > 0\\) . Exemple Mod\u00e9lisons la porte logique A et (non B) via le Perceptron. Quelle valeur de \\(\\vartheta\\) prendre ? Le Perceptron , contrairement au neurone de McCulloch-Pitts, est lui muni d'un algorithme d'entra\u00eenement afin de trouver les poids optimaux pour la pr\u00e9diction. La r\u00e8gle d'apprentissage du Perceptron prend en compte l'erreur faite durant la pr\u00e9diction, et modifie les poids du neurone afin de r\u00e9duire l'erreur. Plus pr\u00e9cis\u00e9ment, le Perceptron re\u00e7oit une observation \u00e0 la fois (ie la batchsize = 1) et sort une pr\u00e9diction \\(\\hat{y}\\) . Pour chaque mauvaise pr\u00e9diction, les poids sont chang\u00e9s en renfor\u00e7ant ceux qui auraient contribu\u00e9 le plus \u00e0 une pr\u00e9diction correcte. Ainsi, pour passer de l'\u00e9tape \\(k\\) \u00e0 l'\u00e9tape \\(k+1\\) , on mets \u00e0 jour les poids via la formule suivante. \\[ w_{i}^{k+1} = w_{i}^{k} + \\eta (y - \\hat{y})x_{i} \\] o\u00f9 : \\(w_{i}\\) est le poids de la connexion \\(i\\) , \\(x_{i}\\) est la valeur d'entr\u00e9e de la connexion \\(i\\) , \\(\\hat{y}\\) est la pr\u00e9diction obtenue par \\(H(\\sum_{i=1}^{m} w_{i}x_{i} - \\vartheta)\\) , \\(y\\) est la cible de la pr\u00e9diction, \\(\\eta\\) est le taux d'appentissage. Remarque Pour le neurone de McCulloch-Pitts, comme pour le Perceptron, la sortie \\(\\hat{y}\\) est binaire. Un neurone de McCulloch-Pitts est un Perceptron o\u00f9 tous les poids sont \u00e9gaux \u00e0 1. \\[ w_{1} = \\cdots = w_{n} = 1 \\] Sch\u00e9ma g\u00e9n\u00e9ral d'un neurone de McCulloch-Pitts (haut) et d'un Perceptron (bas) Un des premiers r\u00e9sultats li\u00e9 au Perceptron est qu'il est capable de mod\u00e9liser et de r\u00e9soudre des probl\u00e8mes o\u00f9 les donn\u00e9es sont lin\u00e9airement s\u00e9parables . D\u00e9finition Une fonction binaire \\[ \\hat{y} \\, : \\, \\mathbf{R}^{n} \\longrightarrow \\lbrace 0,1 \\rbrace \\] est dite Perceptron calculable s'il existe un seuil \\(\\vartheta\\) et des poids \\((w_{1}, \\dots, w_{n}) \\in \\mathbf{R}^{n}\\) tels que l'hyperplan d'\u00e9quation \\[ \\sum_{i=1}^{n} w_{i}x_{i} = \\vartheta \\] divise l'espace \\(\\mathbf{R}^{n}\\) en deux regions \\[ \\mathbf{R}^{n} = R_{0} \\bigcup R_{1} = \\lbrace \\hat{y} =0 \\rbrace \\bigcup \\lbrace \\hat{y}=1 \\rbrace \\] Un ensemble de points \\((x_{1}, \\dots, x_{n}) \\in \\mathbf{R}^{n}\\) pouvant \u00eatre s\u00e9par\u00e9s par une fonction Perceptron calculabe est dit lin\u00e9airement s\u00e9parable . Ensemble de points lin\u00e9airement s\u00e9parables Ensemble de points non lin\u00e9airement s\u00e9parables Remarque Lin\u00e9airement ind\u00e9pendant \\(\\implies\\) Lin\u00e9airement s\u00e9parable. La r\u00e9ciproque est fausse : les points \\(\\lbrace (0,0), (1,0), (0,1) \\rbrace\\) sont lin\u00e9airement s\u00e9parables dans \\(\\mathbf{R}^{2}\\) , mais ne sont pas lin\u00e9airement ind\u00e9pendants. Cette propri\u00e9t\u00e9 de s\u00e9parabilit\u00e9 lin\u00e9aire permet au Perceptron de r\u00e9soudre certains probl\u00e8mes de classification binaire. Th\u00e9or\u00e8me de convergence du Perceptron Etant donn\u00e9 un probl\u00e8me de classification binaire avec des classes lin\u00e9airement s\u00e9parables, si une solution \\((\\vartheta^{\\ast}, w_{1}^{\\ast}, \\dots, w_{n}^{\\ast}) \\in \\mathbf{R}^{n+1}\\) existe, alors l'algorithme du Perceptron trouvera cette solution en un nombre fini \\(h_{\\mathrm{max}}\\) d'it\u00e9rations. En d'autres termes, si on a un ensemble de points que l'on sait lin\u00e9airement s\u00e9parable, et qu'en plus on sait qu'une solution existe, alors le Perceptron la trouvera. Conceptuellement c'est un r\u00e9sultat important. Cependant, ce r\u00e9sultat a deux difficult\u00e9es : Il est n\u00e9c\u00e9ssaire de savoir qu'ne solution \\((\\vartheta^{\\ast}, w_{1}^{\\ast}, \\dots, w_{n}^{\\ast}) \\in \\mathbf{R}^{n+1}\\) existe. En effet, il existe des probl\u00e8mes pour lesquels aucune solution par le Perceptron n'existe. La seconde diffcult\u00e9e est que, m\u00eame si l'on sait que le Perceptron trouvera une solution en un nombre fini d'it\u00e9rations, il nous est impossible de calculer \\(h_{\\mathrm{max}}\\) car il d\u00e9pend du vecteur de solution \\((\\vartheta^{\\ast}, w_{1}^{\\ast}, \\dots, w_{n}^{\\ast}) \\in \\mathbf{R}^{n+1}\\) , qui nous est inconnu. Attention La fonction XOR n'est pas Perceptron calculabe, sa table de v\u00e9rit\u00e9 \u00e9tant la suivante. \\(x_{1}\\) \\(x_{2}\\) \\(x_{1} \\oplus x_{2}\\) 0 0 0 0 1 1 1 0 1 1 1 0 Le probl\u00e8me de la fonction XOR a rapidement montr\u00e9 les limitations du Perceptron. Pour avoir plus de fl\u00e9xibilit\u00e9, l'id\u00e9e est alors d'empiler de fa\u00e7on hi\u00e9rarchique et en plusieurs couches des Perceptrons. Remarque Et les neurosciences dans tout \u00e7a ? De nouvelles recherches en neuroscience ont d\u00e9montr\u00e9es que les dendrites des neurones pyramidaux du n\u00e9ocortex ( la couche de substance grise particuli\u00e8rement d\u00e9velopp\u00e9e chez les mammif\u00e8res et qui forme la paroi des h\u00e9misph\u00e8res c\u00e9r\u00e9braux ) sont en fait capables de classifier des entr\u00e9es non lin\u00e9airement s\u00e9parabes. En d'autres termes, les dendrites sont capables de calculer la fonction XOR , et le cerveau est (encore une fois) bien plus complexe que nous le pensions. Concernant la fonction XOR, il faut un r\u00e9seau de neurones denses \u00e0 2 couches pour pouvoir la calculer. Dendritic action potentials and computation in human layer 2/3 cortical neurons , Albert Gidon, Timothy Adam Zolnik, Pawel Fidzinski, Felix Bolduan, Athanasia Papoutsi, Panayiota Poirazi, Martin Holtkamp, Imre Vida, Matthew Evan Larkum R\u00e9captulatif R\u00e9capitulatif et suite Gen\u00e9ralisation : Les r\u00e9seaux de neurones denses On peut donc r\u00e9sumer la partie pr\u00e9c\u00e9dente dans le diagramme suivant. avec \\(b = -\\vartheta\\) et la fonction de Heaviside \\(H\\) \u00e9tant ici la fonction d'activation \\(f\\) . Attention Le Perceptron ne peut faire que de la classification binaire. Pour r\u00e9soudre le probl\u00e8me de la fonction XOR, l'id\u00e9e est d'empiler de fa\u00e7on hi\u00e9rarchique en plusieurs couches des Perceptrons succ\u00e9ssifs. On parle alors de Perceptron Multicouche (MLP), premier exemple de r\u00e9seau de neurones artificiels (ANN). Pour avoir une notion plus int\u00e9r\u00e9ssante, il est n\u00e9c\u00e9ssaire de modifier la d\u00e9finition du Perceptron. Avant toute modification, posons une d\u00e9finition g\u00e9n\u00e9rale, qui nous sera utile dans toute la suite de la formation. c'est celle de graphe acyclique orient\u00e9 . Structurellement , un MLP, et donc un ANN, est un graphe orient\u00e9 acyclique . D\u00e9finition Un graphe , est une collection \\(G = (S,A)\\) o\u00f9 \\(S\\) correspond \u00e0 la collection des sommets et \\(A\\) correspond \u00e0 la collection des ar\u00eates . Un graphe est dit orient\u00e9 lorsque chacune des ar\u00eates poss\u00e8de une orientation. Un graphe orient\u00e9 est dit acyclique s'il n'y a aucune boucles. D\u00e9finition Un Perceptron Multicouche est un DAG o\u00f9 chaque sommets est un Perceptron. Les neurones correspondent aux sommets et les dendrites et axones correspondent aux ar\u00eates du graphe. Les neurones, ou sommets, sont organis\u00e9s en couches successives reli\u00e9es entres elles par les ar\u00eates, les MLP poss\u00e8dent un point de d\u00e9part, la couche d'entr\u00e9e, et un point d'arriv\u00e9e, la couche de sortie, les couches interm\u00e9diaires sont elles appel\u00e9es les couches cach\u00e9es. G\u00e9n\u00e9raliser la m\u00e9thode d'aprentissage du Perceptron \u00e0 un MLP \u00e0 plusieurs couches cach\u00e9es est compliqu\u00e9e, en partie d\u00fb au nombres importants de param\u00e8tres pr\u00e9sents dans les r\u00e9seaux de neurones. Le travail r\u00e9volutionnaire permettant d'entrainer des ANN avec un nombre quelconque de couches cach\u00e9es en un temps fini, date de 1986. Dans l'article Learning internal representations by error propagations , David Rumelhart, Geoffrey Hinton et Ronald Williams introduise l'algorithme de r\u00e9tropropagation pour l'entra\u00eenement. Cependant, pour que cette algorithme fonctionne, il est n\u00e9c\u00e9ssaire de faire des changements dans la d\u00e9finition du MLP. Voyons les changements \u00e0 \u00e9ffectuer points par points. Fonction d'activation et \u00e9tape feedforward Les fonctions d'activations utilis\u00e9es dans le Perceptron \u00e9tant des fonctions de Heaviside. On cette fonction l\u00e0 n'est pas adapt\u00e9e pour l'algorithme de r\u00e9tropropagation, le point cl\u00e9 de cette algorithme, qui sera d\u00e9taill\u00e9 plus tard, est l'utilisation de la descente du gradient. La fonction de Heaviside \u00e9tant constante par morceaux (et donc une d\u00e9riv\u00e9e nulle en tout point), une telle technique ne marche pas dessus. Il est donc n\u00e9c\u00e9ssaire de remplacer ces fonctions de Heaviside par une autre fonction, la fonction d'activation choisie par Rumelhart, Hinton, et Williams pour la remplacer est la fonction sigmo\u00efde (logistique). \\[ \\begin{array}{ccccc} \\sigma & : & \\mathbf{R} & \\to & [0,1] \\\\ & & x & \\mapsto & \\sigma(x) \\\\ \\end{array} \\] \\[ \\sigma(x) := \\frac{1}{1 + \\exp(-x)} \\] La fonction logistique poss\u00e8de, au contraire de la fonction de Heaviside, une d\u00e9riv\u00e9e bien d\u00e9finie et non nulle en tout point. L'algorithme de r\u00e9tropropagation fonctionne avec de nombreuses autres fonctions d'activations. Avant de d\u00e9finir les autres fonctions, il est utile de distinguer deux types de fonctions d'activations : Les fonctions d'activations uniquement pr\u00e9sentes en sortie de couches cach\u00e9es, Les fonctions d'activations pouvant \u00eatre pr\u00e9sentes aussi en en sortie du DAG. Le deuxi\u00e8me type de fonction d'activation est tr\u00e8s restreint et d\u00e9pend de la probl\u00e9matique que l'on souhaite r\u00e9soudre . Dans le cas d'un probl\u00e8me de r\u00e9gression lin\u00e9aire, aucune fonction d'activation en sortie n'est demand\u00e9e. Dans le cas d'un probl\u00e8me de classification binaire, la fonction d'activation en sortie sera la fonction logistique Attention Et dans le cas d'une classification multinomiale ? Pour une classification multinomiale, la fonction d'activation privil\u00e9gi\u00e9e en sortie du r\u00e9seau est la fonction softmax \\[ \\begin{array}{ccccc} \\mathrm{softmax} & : & \\mathbf{R}^{k} & \\to & [0,1]^{k} \\\\ & & x & \\mapsto & \\mathrm{softmax}(x) \\\\ \\end{array} \\] \\[\\mathrm{softmax}(x) := (\\frac{\\exp(x_{1})}{\\sum_{i=1}^{k}\\exp(x_{i})}, \\dots, \\frac{\\exp(x_{k})}{\\sum_{i=1}^{k}\\exp(x_{i})})\\] Remarque Dans le cas d'un probl\u00e8me de classification binaire, il est aussi possible d'utiliser en sortie la fonction softmax \u00e0 condition d'avoir modifier la cible \\(\\mathbf{y}_{i}\\) par un One-hot Encoding , ce cas l\u00e0 sera tra\u00eet\u00e9 en TP. Dans le cas des fonctions d'activations uniquement pr\u00e9sentes en sortie de couches cach\u00e9es, on a un plus grand choix possibles. Dans la pratique cependant, 2 fonctions d'activations sont plus utilis\u00e9es que les autres. La fonction d'activation devenue un standard est la fonction \\(\\mathrm{ReLU}\\) : Rectified Linear Unit, d\u00e9finie par \\[ \\begin{array}{ccccc} \\mathrm{ReLU} & : & \\mathbf{R} & \\to & \\mathbf{R} \\\\ & & x & \\mapsto & \\mathrm{ReLU}(x) \\\\ \\end{array} \\] \\[\\mathrm{ReLU}(x) := \\max(0,x)\\] Remarque La fonction \\(\\mathrm{ReLU}\\) n'est utilis\u00e9e qu'en sortie des couches cach\u00e9es, et non pas en sortie du r\u00e9seau. La fonction \\(\\mathrm{ReLU}\\) n'est pas diff\u00e9rentiable en 0, et sa d\u00e9riv\u00e9e est nulle pour \\(x<0\\) . Dans la pratique cependant, elle fonctionne tr\u00e8s bien et surtout, sa d\u00e9riv\u00e9e est tr\u00e8s rapide \u00e0 calculer. Un deuxi\u00e8me choix, aussi tr\u00e8s courant, est la fonction tangente hyperbolique, \\(\\tanh\\) . \\[ \\begin{array}{ccccc} \\tanh & : & \\mathbf{R} & \\to & [-1,1] \\\\ & & x & \\mapsto & \\frac{\\mathrm{e}^{x}-\\mathrm{e}^{-x}}{\\mathrm{e}^{x}+\\mathrm{e}^{-x}} \\\\ \\end{array} \\] Remarque Les fonctions d'activations doivent poss\u00e9der les caract\u00e9ristiques suivantes. La fonction doit \u00eatre continue et d\u00e9finie partout, La fonction doit \u00eatre monotone, La fonction ne doit pas \u00eatre lin\u00e9aire, La fonction, et ses d\u00e9riv\u00e9es, doit \u00eatre facilement calculable. Le parcours complet d'une observation \\(\\mathbf{x}_{i}\\) \u00e0 travers le DAG se nomme dans le jargon l'\u00e9tape de feedforward. Pour que cela soit plus clair, voyons celas sur un exemple. Exemple D\u00e9finissons un exemple d'\u00e9tape feedforward. On a deux entr\u00e9es \\(x_{1}, x_{2}\\) , et une sortie \\(\\hat{y}\\) . On peut donc supposer que les observations du dataset sont de la forme \\((x_{1}, x_{2}, y)\\) . Etape 1 : Les features de l'observation \\((x_{1}, x_{2})\\) sont pass\u00e9es en entr\u00e9e, chacune de ces features est envoy\u00e9e \u00e0 chaucn des neurones \\(h_{1}, h_{2}\\) de l'unique couche cach\u00e9e. Les connexions \u00e9tant pond\u00e9r\u00e9es, la r\u00e8gle des noeuds s'applique et au niveau de la couche cach\u00e9e on se retrouve avec les valeurs \\(z_{1}, z_{2}\\) d\u00e9fini\u00e9es par l'\u00e9quation \\((1)\\) , ou de fa\u00e7on \u00e9quivalente par l'\u00e9quation \\((2)\\) sous forme matricielle. La matrice \\(2 \\times 2\\) de l'\u00e9quation \\((2)\\) est la matrice de poids de la couche cach\u00e9e. Etape 2 : En sortie de la couche cach\u00e9e, la fonction d'activation \\(\\sigma^{1}\\) s'applique, on est alors \u00e0 l'\u00e9quation \\((3)\\) avec les valeurs \\((y_{1}, y_{2})\\) . Etape 3 : En arrivant au neurone de sortie, une nouvelle loi des noeuds s'applique \u00e0 l'int\u00e9rieur du neurone rouge, puis la fonction d'activation \\(\\sigma^{2}\\) . D'o\u00f9 l'\u00e9quation \\((4)\\) . Le vecteur \\(\\hat{y}\\) que l'on a en sortie de l'\u00e9tape de feedforward pour l'observation \\(x_{1}, x_{2}\\) est alors cible pr\u00e9dite (ou simplement pr\u00e9diction) par l'ANN. Comment alors mesurer l'erreur faite en pr\u00e9disant \\(\\hat{y}\\) par rapport \u00e0 la cible \\(y\\) ? Exemple Un r\u00e9seau de neurones dense avec 3 couches cach\u00e9es, 5 entr\u00e9es et 3 sorties, on peut supposer que l'on est dans le cas d'un probl\u00e8me de classification avec 3 classes distinctes. Fonction de perte La fonction de perte est l\u00e0 pour calculer l'erreur obtenue entre la pr\u00e9diction et la cible. Elle est traditionnelement not\u00e9e \\(\\mathcal{L}_{\\theta}\\) . Suivant le but du r\u00e9seau de neurone on a plusieurs fonctions de pertes standards. But Fonction de pertes Activation R\u00e9gression Erreur Moyenne Absolue (MAE) aucune R\u00e9gression Erreur Moyenne Quadratique (MSE) aucune Classification Binomiale Entropie Crois\u00e9e Binomiale (BCE) sigmo\u00efde Classification Binomiale (One Hot Encoding) Entropie Crois\u00e9e Cat\u00e9gorielle (CCE) softmax Classification multinomiale Entropie Crois\u00e9e Cat\u00e9gorielle Eparse (SCCE) softmax Classification multinomiale (One Hot Encoding) Entropie Crois\u00e9e Cat\u00e9gorielle (CCE) softmax Dans le cadre des probl\u00e8mes de classification, les noms des fonctions de pertes peut \u00eatre diff\u00e9rents mais la formule est fondamentalement la m\u00eame. les modifications apport\u00e9es ne sont l\u00e0 que pour prendre en compte la forme des pr\u00e9dictions et cibles : est ce que la classe est repr\u00e9sent\u00e9e par un vecteur ou simplement par un nombre ? \\[ MAE := \\frac{1}{N}\\sum_{i=1}^{N} ||y_{i} - \\hat{y}_{i}||_{1} \\] \\[ MSE := \\frac{1}{N}\\sum_{i=1}^{N} ||y_{i} - \\hat{y}_{i}||^{2}_{2} \\] \\[ CE := -\\frac{1}{N}\\sum_{i=1}^{N} \\langle y_{i}, \\log(\\hat{y}_{i}) \\rangle \\] Le nombre \\(N\\) pr\u00e9sent dans les formules ci dessus est la taille du minibatch d'observations, pour l'instant on peut supposer que \\(N=32\\) . Sa d\u00e9finition sera claire par la suite. Remarque Dans le jargon, elle est appel\u00e9e loss function et est traditionnelement not\u00e9e \\(\\mathcal{L}_{\\theta}\\) , o\u00f9 \\(\\theta\\) repr\u00e9sente les poids et biais du r\u00e9seau. On a fait une \u00e9tape de feedforward, on a obtenu une pr\u00e9diction \\(\\hat{y}\\) dont on a calcul\u00e9e l'erreur \\(\\mathcal{L}_{\\theta}(\\hat{y})\\) gr\u00e2ce \u00e0 a fonction de perte \\(\\mathcal{L}_{\\theta}\\) . La question qui se pose maintenant est la suivante. Comment minimiser cette erreur ? Descente du gradient stochastique De fa\u00e7on succinte, on utilise la methode de la technique du gradient coupl\u00e9e \u00e0 une m\u00e9thode efficace pour calculer automatiquement le gradient. Descente du gradient La m\u00e9thode de la descente du gradient est un algorithme d'optimisation permettant de trouver le minimum d'une fonction \\(f\\) . Pour simplifier l'explication, supposons que l'on consid\u00e8re la fonction d'une seule variable. \\[ \\begin{array}{ccccc} C & : & \\mathbf{R} & \\to & \\mathbf{R} \\\\ & & w & \\mapsto & C(w) \\\\ \\end{array} \\] La m\u00e9thode pour trouver un minimum de \\(C\\) est alors d'appliquer l'algorithme suivant : Initialisation Choisir un point de d\u00e9part \\(w \\in \\mathrm{dom}(C)\\) . Choisir un pas \\(\\eta\\) \"tr\u00e8s petit\". et r\u00e9p\u00e9ter : Calculer \\(C'(w)\\) Mettre \u00e0 jour \\(w := w - \\eta C'(w)\\) Si \\(w\\) est un minimum de \\(C\\) , alors \\(C'(w) = 0\\) et l'\u00e9tape 2 de la phase de r\u00e9p\u00e9tition reste bloqu\u00e9e sur \\(w\\) . Exemple de descente du gradient (mlfromscratch) La descente du gradient se g\u00e9n\u00e9ralise de la m\u00eame fa\u00e7on \u00e0 une fonction de plusieurs variables. Pour une fonction \\[f \\, : \\, \\mathbf{R}^{k} \\longrightarrow \\mathbf{R}\\] Les \u00e9tapes 2.a et 2.b ci dessus sont alors remplac\u00e9es par les \u00e9tapes suivantes. Calculer \\(\\nabla f := ( \\frac{\\partial f}{\\partial x_{1}}, \\dots, \\frac{\\partial f}{\\partial x_{k}})\\) Mettre \u00e0 jour \\(w := w - \\eta \\nabla f\\) Le but de la descente du gradient \u00e9tant de d\u00e9terminer le minimum d'une fonction, la question que l'on peut se poser de fa\u00e7on l\u00e9gitime est alorsla suivante : si l'on utilise la descente du gradient ici, quelle fonction souhaite-t-on minimiser ? Dans le cas du Deep Learning, la fonction que l'on cherche \u00e0 minimiser est la fonction de perte moyenne totale . \\[ \\mathcal{L}_{\\theta}^{\\mathrm{tot}} := \\frac{1}{n} \\sum_{i=1}^{n} \\mathcal{L}_{\\theta}(\\hat{y}_{i}) \\] On rappelle que \\(n\\) est le cardinal de \\(\\mathcal{X}\\) , ie le nombre total d'observations dans le dataset. On notera \\(\\theta\\) l'ensemble des param\u00e8tres du r\u00e9seau , on pose \\(p\\) son cardinal, (le nombre total de param\u00e8tres, poids et biais combin\u00e9) il peut aller d'une dizaine \u00e0 plusieurs milliards pour les mod\u00e8les les plus r\u00e9cents. On a donc l'ensemble suivant, \\[ \\theta := \\lbrace w_{1}, \\dots, w_{\\alpha}, b_{1}, \\dots, b_{\\beta} \\rbrace \\quad \\alpha + \\beta = p \\] Reste alors \u00e0 savoir par rapport \u00e0 quelles variables l'on souhaite calculer le gradient. Rapellons nous que dans la fonction de perte, pour une observation donn\u00e9e \\(y_{i}\\) , \\(\\hat{y}_{i}\\) est une combinaison des \u00e9l\u00e9ments de \\(y_{i}\\) et des param\u00e8tres du r\u00e9seau, la valeur de \\(y_{i}\\) \u00e9tant fixe, la seule chose qui peut varier dans la fonction de perte est la valeur des param\u00e8tres \\(\\theta\\) . Remarque Le but de l'algorithme de r\u00e9tropropagation du gradient est de trouver les param\u00e8tres \\(\\theta\\) optimaux pour minimiser la fonction de perte. Le gradient \u00e0 calculer est donc le suivant. \\[ \\nabla_{\\theta} \\mathcal{L}_{\\theta}^{\\mathrm{tot}} := \\begin{pmatrix} \\frac{\\partial \\mathcal{L}_{\\theta}^{\\mathrm{tot}}}{\\partial w_{1}} \\\\ \\frac{\\partial \\mathcal{L}_{\\theta}^{\\mathrm{tot}}}{\\partial w_{2}} \\\\ \\vdots \\\\ \\frac{\\partial \\mathcal{L}_{\\theta}^{\\mathrm{tot}}}{\\partial w_{\\alpha}} \\\\ \\frac{\\partial \\mathcal{L}_{\\theta}^{\\mathrm{tot}}}{\\partial b_{1}} \\\\ \\vdots \\\\ \\frac{\\partial \\mathcal{L}_{\\theta}^{\\mathrm{tot}}}{\\partial b_{\\beta}} \\end{pmatrix} \\] Calculer ce gradient se fait alors via l'algorithme dit d'auto-diff\u00e9rentiation inverse , c'est le choix fait par Tensorflow. Exemple : Graphe de calcul et auto-diff\u00e9rentiation inverse On prend l'exemple de la fonction suivante. \\[ f(x) := \\log(x) + \\sqrt{\\log(x)} \\] On souhaite calculer sa d\u00e9riv\u00e9, son graphe de calcul est alors le suivant. .. figure :: image_module1/autodiff_final.svg :align: center L'algorithme d'auto-diff\u00e9rentiation prend alors la forme suivante. \\[ \\begin{align} (1) \\quad \\frac{\\partial f}{\\partial f} & = 1 \\\\ (2) \\quad \\frac{\\partial f}{\\partial z} & = \\frac{\\partial f}{\\partial f} \\cdot \\frac{\\partial f}{\\partial z} =\\frac{\\partial f}{\\partial f}1 \\\\ (3) \\quad \\frac{\\partial f}{\\partial y} & = \\frac{\\partial f}{\\partial z} \\cdot \\frac{\\partial z}{\\partial y} + \\frac{\\partial f}{\\partial f}\\cdot \\frac{\\partial f}{\\partial y} = \\frac{\\partial f}{\\partial z}\\cdot \\frac{1}{2\\sqrt{y}} + \\frac{\\partial f}{\\partial f}1 \\\\ (4) \\quad \\frac{\\partial f}{\\partial x} & = \\frac{\\partial f}{\\partial y}\\cdot \\frac{\\partial y}{\\partial x} = \\frac{\\partial f}{\\partial y} \\cdot\\frac{1}{x} \\end{align} \\] Le but de la descente du gradient dans l'algorithme de r\u00e9tropropagation est alors de minimiser cette fonction de perte, et donc de minimiser l'erreur moyenne faite durant la pr\u00e9diction . Cependant pour un dataset comprenant plusieurs millions d'observations calculer le gradient complet \\(\\nabla_{\\theta}\\mathcal{L}_{\\theta}\\) est prohibitf. L'id\u00e9e est alors d'\u00e9changer ce gradient complet pour un gradient approximatif mais plus simple \u00e0 calculer . C'est le principe du minibatch. De fa\u00e7on plus d\u00e9taill\u00e9e, voici comment fonctionne l'algorithme : Algorithme de r\u00e9tropropagation L'algorithme consid\u00e8re un minibatch de taile \\(N\\) \u00e0 la fois (par exemple, avec \\(N=32\\) observations \u00e0 chaque fois), lorsque l'on parle de mini-batch de taille \\(N\\) il faut comprendre s\u00e9lection de \\(N\\) observations par un tirage sans remise . Chaque passage du dataset complet s'appelle une \u00e9poque . Durant l'\u00e9tape de feedforward, chaque passage du mini-batch dans une couche du r\u00e9seau le r\u00e9sultat obtenu est conserv\u00e9 en m\u00e9moire. Une fois le mini-batch pass\u00e9 compl\u00e8tement dans l'ANN, la pr\u00e9diction est alors \u00e9valu\u00e9e avec la fonction de perte pour en d\u00e9duire l'erreur de pr\u00e9diction faite par rapport par rapport \u00e0 la cible. L'algorithme calcule alors la contribution de chacun des poids et biais dans le calcul de l'erreur obtenue par la fonction de perte. Une descente du gradient sur la fonction de perte est alors appliqu\u00e9e pour modifier les poids et les biais, et \u00e0 terme minimiser la fonction de perte. La mise \u00e0 jour des param\u00e8tres de l'ANN se faisant suite au passage du mini-batch, la technique de descente du gradient utilis\u00e9e ici est dite descente du gradient stochastique , stochastique faisant r\u00e9f\u00e9rence ici \u00e0 la mani\u00e8re al\u00e9atoire par laquelle sont s\u00e9lectionn\u00e9es les observations composants le mini-batch. Exemple La m\u00e9thode du gradient est utilis\u00e9 pour optimiser les param\u00e8tres du r\u00e9seau de neurones. Les \u00e9tapes sont les suivantes. Comme on travaille en mini-batch de taille \\(N\\) (eg \\(N=32\\) ) on a une valeur d'erreur pour chaque pr\u00e9dictions faite sur ce mini-batch. \\[ \\mathcal{L}_{\\theta}(\\hat{y}_{1}), \\mathcal{L}_{\\theta}(\\hat{y}_{2}), \\dots, \\mathcal{L}_{\\theta}(\\hat{y}_{N}) \\] La fonction que l'on va donc utiliser pour appliquer la m\u00e9thode du gradient est la fonction de perte moyenne sur ce mini-batch. \\[ \\mathcal{L}_{\\theta} := \\frac{1}{N} \\sum_{i=1}^{N} \\mathcal{L}_{\\theta}(\\hat{y}_{i}) \\] Le gradient de cette fonction est alors d\u00e9fini par : \\[ \\nabla_{\\theta} \\mathcal{L}_{\\theta} := \\begin{pmatrix} \\frac{\\partial \\mathcal{L}_{\\theta}}{\\partial w_{1}} \\\\ \\frac{\\partial \\mathcal{L}_{\\theta}}{\\partial w_{2}} \\\\ \\vdots \\\\ \\frac{\\partial \\mathcal{L}_{\\theta}}{\\partial w_{\\alpha}} \\\\ \\frac{\\partial \\mathcal{L}_{\\theta}}{\\partial b_{1}} \\\\ \\vdots \\\\ \\frac{\\partial \\mathcal{L}_{\\theta}}{\\partial b_{\\beta}} \\end{pmatrix} \\] La mise \u00e0 jour des param\u00e8tres se fait alors via la formule suivante : \\[ w_{i} - \\eta \\frac{\\partial \\mathcal{L}_{\\theta}}{\\partial w_{i}}(\\theta) \\] \\[ b_{i} - \\eta \\frac{\\partial \\mathcal{L}_{\\theta}}{\\partial b_{i}}(\\theta) \\] \\(\\eta\\) est ici un nombre r\u00e9el que l'on appelle le taux d'apprentissage, il n'est pas appris par l'algorithme et doit \u00eatre fix\u00e9 \u00e0 la main (c'est un hyperparam\u00e8tre). Pourquoi choisir une m\u00e9thode stochastique ? Etant donn\u00e9e une fonction diff\u00e9rentiable, il est th\u00e9oriquement possible de trouver son minimum de fa\u00e7on purement analytique : une fonction \\(f : \\mathbf{R} \\rightarrow \\mathbf{R}\\) poss\u00e8de un extremum en un point \\(x\\) si sa d\u00e9riv\u00e9e \\(f'(x)\\) est nulle. Une fois trouv\u00e9 tous ces points on prend celui pour lequel \\(f(x)\\) est la plus petite valeur. Dans le cadre des r\u00e9seaux de neurones, cela revient \u00e0 devoir r\u00e9soudre \\(\\nabla \\mathcal{L}_{\\theta} = 0\\) . C'est une \u00e9quation polynomiale en \\(p\\) variables, o\u00f9 \\(p\\) est le cardinal de \\(\\theta\\) ensemble des param\u00e8tres du r\u00e9seau. Premi\u00e8rement, si cela est faisable pour \\(p=2\\) ou \\(p=3\\) , c'est difficilement r\u00e9alisable dans la pratique d'une r\u00e9seau de neurones o\u00f9 \\(p\\) d\u00e9passe facilement la centaine de milliers. Deuxi\u00e8mement, effectuer une descente du gradient classique supposerait d'avoir calcul\u00e9 les pr\u00e9dictions sur l'ensemble du dataset, et de garder en m\u00e9moire ces valeurs afin de calculer \\(\\nabla \\mathcal{L}_{\\theta}\\) . Du point de vue de la complexit\u00e9 algorithmique, le co\u00fbt de calcul de \\(\\nabla \\mathcal{L}_{\\theta}=0\\) cro\u00eet alors de fa\u00e7on lin\u00e9aire avec la taille du dataset . Dans une m\u00e9thode stochastique, la taille du mini-batch \u00e9tant fix\u00e9e (eg \\(N=32\\) ) et relativement petite par rapport \u00e0 la taille du dataset, la compl\u00e9xit\u00e9 est moindre et constante tout au long de l'algorithme. Les mises \u00e0 jour des param\u00e8tres \u00e9tant plus fr\u00e9quentes, l'algorithme converge plus rapidement vers un optimum. Remarque La descente du gradient, stochastique ou non, est \u00e0 la base une m\u00e9thode d' optimisation convexe , hors les fonctions de pertes utilis\u00e9es dans la pratique ne sont pas convexes . On se retrouve donc g\u00e9n\u00e9ralement uniquement avec des minima locaux pour la fonction de perte. Dans la pratique ce n'est pas un soucis, et de nombreuses techniques d'optimisation ont \u00e9t\u00e9 introduites pour pouvoir converger vers un minimum global au lieu de \"rester coinc\u00e9 dans un minimum local\". M\u00e9thodes que l'on verra dans les modules suivants. Sym\u00e9trie des poids La descente du gradient stochastique, n'est qu'une des m\u00e9thodes d'optimisation afin de minimiser la fonction de perte. Il existe aujourd'hui de nombreux optimiseurs pour la descente du gradient. Exemple D\u00e9finissons un exemple de l'\u00e9tape de r\u00e9tropropagation du gradient. \\[ \\begin{align} \\frac{\\partial \\mathcal{L}_{\\vartheta}}{ \\partial w_{1,1}^{1}} = & \\frac{\\partial \\mathcal{L}_{\\vartheta}}{\\partial s} \\cdot \\frac{\\partial s}{\\partial h_{1}^{2}} \\cdot \\frac{\\partial h_{1}^{2}}{\\partial h_{1}^{1}} \\cdot \\frac{\\partial h_{1}^{1}}{\\partial w_{1,1}^{1}} \\\\ + & \\frac{\\partial \\mathcal{L}_{\\vartheta}}{\\partial s} \\cdot \\frac{\\partial s}{\\partial h_{2}^{2}} \\cdot \\frac{\\partial h_{2}^{2}}{\\partial h_{1}^{1}} \\cdot \\frac{\\partial h_{1}^{1}}{\\partial w_{1,1}^{1}} \\end{align} \\] \\[ w_{1,1}^{1} \\leftarrow w_{1,1}^{1} - \\eta \\frac{\\partial \\mathcal{L}_{\\vartheta}}{ \\partial w_{1,1}^{1}}. \\] Les neurones denses sont une g\u00e9n\u00e9ralisation tr\u00e8s puissante des MLP, car ce sont des approximateurs universels . Th\u00e9or\u00e8me d'approximation universelle de Kolmogorov Toute fonction continue d\u00e9finie sur un compact \\(K \\subset \\mathbf{R}^{r}\\) peut \u00eatre uniform\u00e9ment approxim\u00e9e par un r\u00e9seau de neurones denses avec une couche cach\u00e9e. R\u00e9sum\u00e9 Math\u00e9matiquement, un MLP peut se repr\u00e9senter par la fonction suivante. \\[ \\begin{array}{ccccc} f_{NN} & : & \\mathbf{R}^{m} & \\to & \\mathbf{R}^{k} \\\\ & & \\mathbf{x} & \\mapsto & f_{NN}(\\mathbf{x}) \\\\ \\end{array} \\] \\[ \\hat{\\mathbf{y}} := f_{NN}(\\mathbf{x}) = \\sigma^{r} \\circ \\cdots \\circ \\sigma^{1} (\\mathbf{x}) \\] L'entier \\(m\\) d\u00e9pend du nombre de features dans le dataset, l'entier \\(k\\) d\u00e9pend lui du probl\u00e8me consid\u00e9r\u00e9. Le nombre de fonctions \\(\\sigma^{i}\\) d\u00e9pend de l'architecture du r\u00e9seau et correspond au nombre de couches cach\u00e9es. \\[ \\mathbf{y}^{\\ell} := \\sigma^{\\ell}(\\mathbf{X}\\mathbf{W}_{\\ell} + \\mathbf{b}_{\\ell}) \\] O\u00f9 \\(\\mathbf{W}_{\\ell}\\) correspond \u00e0 la matrice de poids de la couche \\(\\ell\\) et \\(\\mathbf{b}_{\\ell}\\) au vecteur de biais correspondant. On a Une ligne par features dans \\(\\mathbf{X}\\) , Une colonne par neurones dans la couche cach\u00e9e, Autant de biais que de neurones dans la couche cach\u00e9e. \\[ \\begin{equation*} \\mathbf{W}_{\\ell} = \\begin{pmatrix} w_{1,1}^{\\ell} & w_{1,2}^{\\ell} & \\cdots & w_{1,r}^{\\ell} \\\\ w_{2,1}^{\\ell} & w_{2,2}^{\\ell} & \\cdots & w_{2,r}^{\\ell} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ w_{l,1}^{\\ell} & w_{l,2}^{\\ell} & \\cdots & w_{l,r}^{\\ell} \\end{pmatrix}\\end{equation*} \\in \\mathcal{M}_{l,r}(\\mathbf{R}) \\quad \\mathbf{b}_{\\ell} = \\begin{pmatrix}b_{1}^{\\ell} & b_{2}^{i} & \\cdots & b_{r}^{\\ell} \\end{pmatrix} \\] La topologie du r\u00e9seau : Le nombres de neurones, de couches, de neurones par couches, et d'arr\u00eates d\u00e9pendent du probl\u00e8me consid\u00e9r\u00e9. Il existe toutefois des architectures connues et sp\u00e9cialis\u00e9es dans certains probl\u00e8mes. Certaines couches de neurones sont ainsi sp\u00e9cialis\u00e9es dans le traitement d'images, d'autres encore dans le traitement des s\u00e9ries temporelles. Exemple Un r\u00e9seau de neurones dense avec 3 couches cach\u00e9es, 5 entr\u00e9es et 3 sorties, on peut supposer que l'on est dans le cas d'un probl\u00e8me de classification avec 3 classes distinctes. La premi\u00e8re couche cach\u00e9e a pour matrice de poids une matrice de taille \\(5\\times 10\\) , \\(\\mathbf{W}_{1} \\in \\mathcal{M}_{5,10}(\\mathbf{R})\\) , La deuxi\u00e8me couche cach\u00e9e a pour matrice de poids une matrice de taille \\(10\\times 10\\) , \\(\\mathbf{W}_{2} \\in \\mathcal{M}_{10,10}(\\mathbf{R})\\) , La trois\u00e8me couche cach\u00e9e a pour matrice de poids une matrice de taille \\(10\\times 10\\) , \\(\\mathbf{W}_{3} \\in \\mathcal{M}_{10,10}(\\mathbf{R})\\) , La couche de sortie a pour matrice de poids une matrice de taille \\(10\\times 3\\) , \\(\\mathbf{W}_{4} \\in \\mathcal{M}_{10,3}(\\mathbf{R})\\) . Concernant les biais on a des vecteurs : \\(\\mathbf{b}_{1} \\in \\mathbf{R}^{10}\\) pour la premi\u00e8re couche cach\u00e9e, \\(\\mathbf{b}_{2} \\in \\mathbf{R}^{10}\\) pour la deuxi\u00e8me couche cach\u00e9e, \\(\\mathbf{b}_{3} \\in \\mathbf{R}^{10}\\) pour la troisi\u00e8me couche cach\u00e9e, \\(\\mathbf{b}_{4} \\in \\mathbf{R}^{3}\\) pour la couche de sortie. Ce qui nous fait un nombre total de param\u00e8tres \u00e9gal \u00e0 \\(\\dim( \\mathcal{M}_{5,10}(\\mathbf{R})) + \\dim(\\mathbf{R}^{10}) + \\dim( \\mathcal{M}_{10,10}(\\mathbf{R})) + \\dim(\\mathbf{R}^{10}) +\\dim( \\mathcal{M}_{10,10}(\\mathbf{R})) + \\\\ \\dim(\\mathbf{R}^{10}) + \\dim( \\mathcal{M}_{10,3}(\\mathbf{R})) + \\dim(\\mathbf{R}^{3}) = 313\\) 313 param\u00e8tres, ce qui est loin d'\u00eatre \u00e9norme. En python, avec tensorflow, un tel r\u00e9seau ce code de la mani\u00e8re suivante. model = models . Sequential ([ Input ( shape = ( 5 ,), name = 'Input' ), Dense ( 10 ), Activation ( 'relu' ), Dense ( 10 ), Activation ( 'relu' ), Dense ( 10 ), Activation ( 'relu' ), Dense ( 3 ), Activation ( 'softmax' ) ], name = 'SeqAPI' )","title":"Th\u00e9orie"},{"location":"test/#module-1-introduction-au-deep-learning-prise-en-main-de-tensorflow-et-keras","text":"","title":"Module 1 : Introduction au deep learning, prise en main de Tensorflow et Keras"},{"location":"test/#preliminaires-notations-et-conventions","text":"Dans la suite de ces modules, on se place de le cadre d'un apprentissage dit supervis\u00e9 , on consid\u00e9rera donc la probl\u00e9matique suivante : Probl\u00e9matique On note \\(\\mathbf{R}^{j}\\) l'espace vectoriel r\u00e9el de dimension \\(j\\) . Etant donn\u00e9 le dataset (fini) suivant. \\[ \\mathcal{X} = \\lbrace (\\mathbf{x}_{i}, \\mathbf{y}_{i})\\rbrace_{i \\in I} \\quad (\\mathbf{x}_{i}, \\mathbf{y}_{i}) \\in \\mathbf{R}^{m} \\times \\mathbf{R}^{k} \\] On suppose que \\(\\mathbf{x}_{i}\\) et \\(\\mathbf{y}_{i}\\) sont reli\u00e9s entre eux par une fonction inconnue \\(f : \\mathbf{R}^{m} \\rightarrow \\mathbf{R}^{k}\\) v\u00e9rifiant la relation suivante. \\[ f(\\mathbf{x}_{i}) = \\mathbf{y}_{i} + \\varepsilon \\] D\u00e9terminer un algorithme estimant \\(f\\) , c'est \u00e0 dire produisant une fonction \\[ \\hat{f} : \\mathbf{R}^{m} \\rightarrow \\mathbf{R}^{k} \\] telle que \\(\\hat{f}(\\mathbf{x}_{i}) = \\hat{\\mathbf{y}}_{i}\\) avec \\(\\hat{\\mathbf{y}}_{i} \\simeq \\mathbf{y}_{i}\\) . Pour d\u00e9terminer \\(\\hat{f}\\) , on se place alors dans le cadre des r\u00e9seaux de neurones. On utilisera les conventions suivantes. \\(I = \\lbrace 1, \\dots, n \\rbrace\\) est un ensemble discret fini, \\(|I| = n\\) est le nombre d' observations dans le dataset. Le couple \\((\\mathbf{x}_{i}, \\mathbf{y}_{i})\\) est alors appel\u00e9 la \\(i\\) -i\u00e8me observation du dataset. \\(\\mathbf{x}_{i} = (x_{i,1}, \\dots, x_{i,m}) \\in \\mathbf{R}^{m}\\) est l'ensemble des features (caract\u00e9ristiques) de la \\(i\\) -i\u00e8me observation du dataset et \\(\\mathbf{y}_{i} = (y_{i,1}, \\dots, y_{i,k}) \\in \\mathbf{R}^{k}\\) est la cible de la \\(i\\) -i\u00e8me observation du dataset. La fonction \\(\\hat{f}\\) est un mod\u00e8le de \\(f\\) , et \\(\\hat{f}(\\mathbf{x}_{i}) = \\hat{\\mathbf{y}}_{i}\\) est une pr\u00e9diction .","title":"Pr\u00e9liminaires, notations et conventions"},{"location":"test/#le-commencement-du-debut-les-neurosciences-le-fonctionnement-dun-neurone-biologique","text":"Avant de parler des neurones artificiels, jetons un coup d'\u0153il rapide sur un neurone biologique. Il s'agit d'une cellule d'apparence inhabituelle que l'on trouve surtout dans les cerveaux d'animaux. Elle est compos\u00e9e d'un corps cellulaire contenant le noyau et la plupart des \u00e9l\u00e9ments du complexe cellulaire, de nombreuses extensions de ramification appel\u00e9es dendrites , plus une tr\u00e8s longue extension appel\u00e9e l' axone . La longueur de l'axone peut \u00eatre juste quelques fois plus longue que la cellule, ou jusqu'\u00e0 des dizaines de milliers de fois plus. Pr\u00e8s de son extr\u00e9mit\u00e9, l'axone se d\u00e9tache en de nombreuses branches appel\u00e9es t\u00e9lodendries , et \u00e0 l'extr\u00e9mit\u00e9 de ces branches se trouvent de minuscules structures appel\u00e9es bornes synaptiques (ou simplement synapses ), qui sont connect\u00e9es \u00e0 la dendrite ou aux corps d'autres neurones. Les neurones biologiques produisent de courtes impulsions \u00e9lectrique appel\u00e9es potentiels d'action (PA, ou simplement des signaux) qui se d\u00e9placent le long des axones et font en sorte que les synapses \u00e9mettent des signaux chimiques appel\u00e9s neurotransmetteurs. Quand un neurone re\u00e7oit une quantit\u00e9 suffisante de ces neurotransmetteurs en quelques millisecondes, il envoie ses propres impulsions \u00e9lectriques (en fait, cela d\u00e9pend des neurotransmetteurs, car certains d'entre eux emp\u00eachent le neurone de s'activer). Ainsi, les neurones biologiques individuels semblent se comporter de mani\u00e8re assez simple, mais ils sont organis\u00e9s en un vaste r\u00e9seau de plusieurs milliards , chaque neurone \u00e9tant g\u00e9n\u00e9ralement connect\u00e9 \u00e0 des milliers d'autres neurones. Des calculs tr\u00e8s complexes peuvent \u00eatre effectu\u00e9s par un r\u00e9seau de neurones assez simples, de la m\u00eame fa\u00e7on que d'une fourmili\u00e8re peut \u00e9merger les efforts combin\u00e9s de simples fourmis. L'architecture des r\u00e9seaux neuronaux biologiques (BNN) fait toujours l'objet de recherches actives, mais certaines parties du cerveau ont \u00e9t\u00e9 cartographi\u00e9es et il semble que les neurones sont souvent organis\u00e9s en couches cons\u00e9cutives, sp\u00e9cialement dans le cortex c\u00e9r\u00e9bral (la couche externe de votre cerveau).","title":"Le commencement du d\u00e9but : les neurosciences &amp; le fonctionnement d'un neurone biologique"},{"location":"test/#le-neurone-de-mcculloch-pitts-et-le-perceptron","text":"L'id\u00e9e premi\u00e8re de laquelle d\u00e9coule l'invention des neurones artificiels est la volont\u00e9e d'avoir un algorithme de classification binaire.","title":"Le neurone de McCulloch-Pitts et le perceptron"},{"location":"test/#le-neurone-de-mcculloch-pitts","text":"Le premier article scientifique mod\u00e9lisant de fa\u00e7on math\u00e9matique un neurone biologique a \u00e9t\u00e9 r\u00e9dig\u00e9 en 1943 par le neurobiologiste Warren McCulloch et le math\u00e9maticien Walter Pitts . Le neurone de McCulloch-Pitts est simple : Le neurone correspond \u00e0 une fonction ayant une ou plusieurs entr\u00e9e binaires et une sortie binaire (0 ou 1). Le neurone ne s'active (produit une sortie) que si le nombre d'entr\u00e9e active d\u00e9passe un certain seuil. On rappelle que la fonction de Heaviside \\(H\\) est d\u00e9finie par : \\[ \\begin{array}{ccccc} H & : & \\mathbf{R} & \\to & [0,1] \\\\ & & x & \\mapsto & H(x) \\\\ \\end{array} \\] avec \\[ H(x) = \\begin{cases} 1 & x \\geq 0, \\\\ 0 & x < 0.\\end{cases} \\] Remarque Un neurone de McCulloch-Pitts est donn\u00e9 par : des entr\u00e9es binaires \\((x_{1}, \\dots, x_{m})\\) , un r\u00e9el \\(\\vartheta \\in \\mathbf{R}\\) , une sortie \\(\\hat{y}\\) , d\u00e9finie par l'\u00e9quation suivante. \\[ \\hat{y} = H(\\sum_{i=1}^{m} x_{i} - \\vartheta), \\quad \\forall i \\in I, x_{i} \\in \\lbrace 0,1 \\rbrace \\] o\u00f9 \\(H\\) est la fonction de Heaviside, et \\(\\vartheta\\) est le seuil. On dit que le neurone s'active si \\(\\sum_{i=1}^{m} x_{i} - \\vartheta > 0\\) . Le neurone tel que d\u00e9fini par McCulloch et Pitts est consid\u00e9r\u00e9 comme une simple porte logique : il n'y a pas d'algorithme associ\u00e9 afin de l'entra\u00eener. Ils montr\u00e8rent cependant qu'un r\u00e9seau constitu\u00e9 des neurones formels de leur invention a la m\u00eame puissance de calcul qu'une machine de Turing, ie ce r\u00e9seau est capable de calculer toutes les propositions logiques. Exemple Mod\u00e9lisons les portes logiques ET et OU via les neurones de McCulloch-Pitts. Quelle valeur de \\(\\vartheta\\) prendre ? D\u00e9finition La fonction brisant la lin\u00e9arit\u00e9 \u00e0 la sortie du neurone, dans notre cas pour l'instant la fonction de Heaviside \\(H\\) , sera appel\u00e9e fonction d'activation du neurone. Attention Le neurone de McCulloch Pitts poss\u00e8de les limites suivantes : Impossibilit\u00e9 de fournir des entr\u00e9es non bool\u00e9ennes. Le seuil doit toujours \u00eatre d\u00e9fini manuellement. Toutes les entr\u00e9es sont \u00e9galement importante, on ne peut pas assigner une importance plus grande \u00e0 certaines entr\u00e9es.","title":"Le neurone de McCulloch-Pitts"},{"location":"test/#le-perceptron","text":"En 1958, puis 1962, Frank Rosenblatt g\u00e9n\u00e9ralise les travaux de McCulloch et Pitts en d\u00e9veloppant le Perceptron . Le Perceptron de Rosenblatt est essentiellement un neurone de McCulloch-Pitts, o\u00f9 les entr\u00e9es \\((x_{1}, \\dots, x_{m})\\) peuvent cette fois ci prendre des valeurs r\u00e9elles. De plus, chaque entr\u00e9e est maintenant pond\u00e9r\u00e9e, le poids \\(w_{i}\\) \u00e9tant lui aussi \u00e0 valeur r\u00e9elle. Un poids positif ( \\(w_{i} > 0\\) ) refl\u00e9tant une synapse excitatrice, tandis qu'un poids n\u00e9gatif ( \\(w_{i} < 0\\) ) repr\u00e9sente lui une synapse inhibitrice. D\u00e9finition Un Perceptron est donn\u00e9 par : des entr\u00e9es \\((x_{1}, \\dots, x_{m}) \\in \\mathbf{R}^{m}\\) , des poids \\((w_{1}, \\dots, w_{m}) \\in \\mathbf{R}^{m}\\) , un r\u00e9el \\(\\vartheta \\in \\mathbf{R}\\) , une sortie \\(\\hat{y}\\) , d\u00e9finie par l'\u00e9quation suivante. \\[ \\hat{y} = H(\\sum_{i=1}^{m} w_{i}x_{i} - \\vartheta), \\forall i \\in I, (w_{i}, x_{i}) \\in \\mathbf{R}^{2} \\] o\u00f9 \\(H\\) est la fonction de Heavyside, et \\(\\vartheta\\) est le seuil. On dit que le neurone s'active si \\(\\sum_{i=1}^{m} w_{i}x_{i} - \\vartheta > 0\\) . Exemple Mod\u00e9lisons la porte logique A et (non B) via le Perceptron. Quelle valeur de \\(\\vartheta\\) prendre ? Le Perceptron , contrairement au neurone de McCulloch-Pitts, est lui muni d'un algorithme d'entra\u00eenement afin de trouver les poids optimaux pour la pr\u00e9diction. La r\u00e8gle d'apprentissage du Perceptron prend en compte l'erreur faite durant la pr\u00e9diction, et modifie les poids du neurone afin de r\u00e9duire l'erreur. Plus pr\u00e9cis\u00e9ment, le Perceptron re\u00e7oit une observation \u00e0 la fois (ie la batchsize = 1) et sort une pr\u00e9diction \\(\\hat{y}\\) . Pour chaque mauvaise pr\u00e9diction, les poids sont chang\u00e9s en renfor\u00e7ant ceux qui auraient contribu\u00e9 le plus \u00e0 une pr\u00e9diction correcte. Ainsi, pour passer de l'\u00e9tape \\(k\\) \u00e0 l'\u00e9tape \\(k+1\\) , on mets \u00e0 jour les poids via la formule suivante. \\[ w_{i}^{k+1} = w_{i}^{k} + \\eta (y - \\hat{y})x_{i} \\] o\u00f9 : \\(w_{i}\\) est le poids de la connexion \\(i\\) , \\(x_{i}\\) est la valeur d'entr\u00e9e de la connexion \\(i\\) , \\(\\hat{y}\\) est la pr\u00e9diction obtenue par \\(H(\\sum_{i=1}^{m} w_{i}x_{i} - \\vartheta)\\) , \\(y\\) est la cible de la pr\u00e9diction, \\(\\eta\\) est le taux d'appentissage. Remarque Pour le neurone de McCulloch-Pitts, comme pour le Perceptron, la sortie \\(\\hat{y}\\) est binaire. Un neurone de McCulloch-Pitts est un Perceptron o\u00f9 tous les poids sont \u00e9gaux \u00e0 1. \\[ w_{1} = \\cdots = w_{n} = 1 \\] Sch\u00e9ma g\u00e9n\u00e9ral d'un neurone de McCulloch-Pitts (haut) et d'un Perceptron (bas) Un des premiers r\u00e9sultats li\u00e9 au Perceptron est qu'il est capable de mod\u00e9liser et de r\u00e9soudre des probl\u00e8mes o\u00f9 les donn\u00e9es sont lin\u00e9airement s\u00e9parables . D\u00e9finition Une fonction binaire \\[ \\hat{y} \\, : \\, \\mathbf{R}^{n} \\longrightarrow \\lbrace 0,1 \\rbrace \\] est dite Perceptron calculable s'il existe un seuil \\(\\vartheta\\) et des poids \\((w_{1}, \\dots, w_{n}) \\in \\mathbf{R}^{n}\\) tels que l'hyperplan d'\u00e9quation \\[ \\sum_{i=1}^{n} w_{i}x_{i} = \\vartheta \\] divise l'espace \\(\\mathbf{R}^{n}\\) en deux regions \\[ \\mathbf{R}^{n} = R_{0} \\bigcup R_{1} = \\lbrace \\hat{y} =0 \\rbrace \\bigcup \\lbrace \\hat{y}=1 \\rbrace \\] Un ensemble de points \\((x_{1}, \\dots, x_{n}) \\in \\mathbf{R}^{n}\\) pouvant \u00eatre s\u00e9par\u00e9s par une fonction Perceptron calculabe est dit lin\u00e9airement s\u00e9parable . Ensemble de points lin\u00e9airement s\u00e9parables Ensemble de points non lin\u00e9airement s\u00e9parables Remarque Lin\u00e9airement ind\u00e9pendant \\(\\implies\\) Lin\u00e9airement s\u00e9parable. La r\u00e9ciproque est fausse : les points \\(\\lbrace (0,0), (1,0), (0,1) \\rbrace\\) sont lin\u00e9airement s\u00e9parables dans \\(\\mathbf{R}^{2}\\) , mais ne sont pas lin\u00e9airement ind\u00e9pendants. Cette propri\u00e9t\u00e9 de s\u00e9parabilit\u00e9 lin\u00e9aire permet au Perceptron de r\u00e9soudre certains probl\u00e8mes de classification binaire. Th\u00e9or\u00e8me de convergence du Perceptron Etant donn\u00e9 un probl\u00e8me de classification binaire avec des classes lin\u00e9airement s\u00e9parables, si une solution \\((\\vartheta^{\\ast}, w_{1}^{\\ast}, \\dots, w_{n}^{\\ast}) \\in \\mathbf{R}^{n+1}\\) existe, alors l'algorithme du Perceptron trouvera cette solution en un nombre fini \\(h_{\\mathrm{max}}\\) d'it\u00e9rations. En d'autres termes, si on a un ensemble de points que l'on sait lin\u00e9airement s\u00e9parable, et qu'en plus on sait qu'une solution existe, alors le Perceptron la trouvera. Conceptuellement c'est un r\u00e9sultat important. Cependant, ce r\u00e9sultat a deux difficult\u00e9es : Il est n\u00e9c\u00e9ssaire de savoir qu'ne solution \\((\\vartheta^{\\ast}, w_{1}^{\\ast}, \\dots, w_{n}^{\\ast}) \\in \\mathbf{R}^{n+1}\\) existe. En effet, il existe des probl\u00e8mes pour lesquels aucune solution par le Perceptron n'existe. La seconde diffcult\u00e9e est que, m\u00eame si l'on sait que le Perceptron trouvera une solution en un nombre fini d'it\u00e9rations, il nous est impossible de calculer \\(h_{\\mathrm{max}}\\) car il d\u00e9pend du vecteur de solution \\((\\vartheta^{\\ast}, w_{1}^{\\ast}, \\dots, w_{n}^{\\ast}) \\in \\mathbf{R}^{n+1}\\) , qui nous est inconnu. Attention La fonction XOR n'est pas Perceptron calculabe, sa table de v\u00e9rit\u00e9 \u00e9tant la suivante. \\(x_{1}\\) \\(x_{2}\\) \\(x_{1} \\oplus x_{2}\\) 0 0 0 0 1 1 1 0 1 1 1 0 Le probl\u00e8me de la fonction XOR a rapidement montr\u00e9 les limitations du Perceptron. Pour avoir plus de fl\u00e9xibilit\u00e9, l'id\u00e9e est alors d'empiler de fa\u00e7on hi\u00e9rarchique et en plusieurs couches des Perceptrons. Remarque Et les neurosciences dans tout \u00e7a ? De nouvelles recherches en neuroscience ont d\u00e9montr\u00e9es que les dendrites des neurones pyramidaux du n\u00e9ocortex ( la couche de substance grise particuli\u00e8rement d\u00e9velopp\u00e9e chez les mammif\u00e8res et qui forme la paroi des h\u00e9misph\u00e8res c\u00e9r\u00e9braux ) sont en fait capables de classifier des entr\u00e9es non lin\u00e9airement s\u00e9parabes. En d'autres termes, les dendrites sont capables de calculer la fonction XOR , et le cerveau est (encore une fois) bien plus complexe que nous le pensions. Concernant la fonction XOR, il faut un r\u00e9seau de neurones denses \u00e0 2 couches pour pouvoir la calculer. Dendritic action potentials and computation in human layer 2/3 cortical neurons , Albert Gidon, Timothy Adam Zolnik, Pawel Fidzinski, Felix Bolduan, Athanasia Papoutsi, Panayiota Poirazi, Martin Holtkamp, Imre Vida, Matthew Evan Larkum R\u00e9captulatif R\u00e9capitulatif et suite","title":"Le Perceptron"},{"location":"test/#generalisation-les-reseaux-de-neurones-denses","text":"On peut donc r\u00e9sumer la partie pr\u00e9c\u00e9dente dans le diagramme suivant. avec \\(b = -\\vartheta\\) et la fonction de Heaviside \\(H\\) \u00e9tant ici la fonction d'activation \\(f\\) . Attention Le Perceptron ne peut faire que de la classification binaire. Pour r\u00e9soudre le probl\u00e8me de la fonction XOR, l'id\u00e9e est d'empiler de fa\u00e7on hi\u00e9rarchique en plusieurs couches des Perceptrons succ\u00e9ssifs. On parle alors de Perceptron Multicouche (MLP), premier exemple de r\u00e9seau de neurones artificiels (ANN). Pour avoir une notion plus int\u00e9r\u00e9ssante, il est n\u00e9c\u00e9ssaire de modifier la d\u00e9finition du Perceptron. Avant toute modification, posons une d\u00e9finition g\u00e9n\u00e9rale, qui nous sera utile dans toute la suite de la formation. c'est celle de graphe acyclique orient\u00e9 . Structurellement , un MLP, et donc un ANN, est un graphe orient\u00e9 acyclique . D\u00e9finition Un graphe , est une collection \\(G = (S,A)\\) o\u00f9 \\(S\\) correspond \u00e0 la collection des sommets et \\(A\\) correspond \u00e0 la collection des ar\u00eates . Un graphe est dit orient\u00e9 lorsque chacune des ar\u00eates poss\u00e8de une orientation. Un graphe orient\u00e9 est dit acyclique s'il n'y a aucune boucles. D\u00e9finition Un Perceptron Multicouche est un DAG o\u00f9 chaque sommets est un Perceptron. Les neurones correspondent aux sommets et les dendrites et axones correspondent aux ar\u00eates du graphe. Les neurones, ou sommets, sont organis\u00e9s en couches successives reli\u00e9es entres elles par les ar\u00eates, les MLP poss\u00e8dent un point de d\u00e9part, la couche d'entr\u00e9e, et un point d'arriv\u00e9e, la couche de sortie, les couches interm\u00e9diaires sont elles appel\u00e9es les couches cach\u00e9es. G\u00e9n\u00e9raliser la m\u00e9thode d'aprentissage du Perceptron \u00e0 un MLP \u00e0 plusieurs couches cach\u00e9es est compliqu\u00e9e, en partie d\u00fb au nombres importants de param\u00e8tres pr\u00e9sents dans les r\u00e9seaux de neurones. Le travail r\u00e9volutionnaire permettant d'entrainer des ANN avec un nombre quelconque de couches cach\u00e9es en un temps fini, date de 1986. Dans l'article Learning internal representations by error propagations , David Rumelhart, Geoffrey Hinton et Ronald Williams introduise l'algorithme de r\u00e9tropropagation pour l'entra\u00eenement. Cependant, pour que cette algorithme fonctionne, il est n\u00e9c\u00e9ssaire de faire des changements dans la d\u00e9finition du MLP. Voyons les changements \u00e0 \u00e9ffectuer points par points.","title":"Gen\u00e9ralisation : Les r\u00e9seaux de neurones denses"},{"location":"test/#fonction-dactivation-et-etape-feedforward","text":"Les fonctions d'activations utilis\u00e9es dans le Perceptron \u00e9tant des fonctions de Heaviside. On cette fonction l\u00e0 n'est pas adapt\u00e9e pour l'algorithme de r\u00e9tropropagation, le point cl\u00e9 de cette algorithme, qui sera d\u00e9taill\u00e9 plus tard, est l'utilisation de la descente du gradient. La fonction de Heaviside \u00e9tant constante par morceaux (et donc une d\u00e9riv\u00e9e nulle en tout point), une telle technique ne marche pas dessus. Il est donc n\u00e9c\u00e9ssaire de remplacer ces fonctions de Heaviside par une autre fonction, la fonction d'activation choisie par Rumelhart, Hinton, et Williams pour la remplacer est la fonction sigmo\u00efde (logistique). \\[ \\begin{array}{ccccc} \\sigma & : & \\mathbf{R} & \\to & [0,1] \\\\ & & x & \\mapsto & \\sigma(x) \\\\ \\end{array} \\] \\[ \\sigma(x) := \\frac{1}{1 + \\exp(-x)} \\] La fonction logistique poss\u00e8de, au contraire de la fonction de Heaviside, une d\u00e9riv\u00e9e bien d\u00e9finie et non nulle en tout point. L'algorithme de r\u00e9tropropagation fonctionne avec de nombreuses autres fonctions d'activations. Avant de d\u00e9finir les autres fonctions, il est utile de distinguer deux types de fonctions d'activations : Les fonctions d'activations uniquement pr\u00e9sentes en sortie de couches cach\u00e9es, Les fonctions d'activations pouvant \u00eatre pr\u00e9sentes aussi en en sortie du DAG. Le deuxi\u00e8me type de fonction d'activation est tr\u00e8s restreint et d\u00e9pend de la probl\u00e9matique que l'on souhaite r\u00e9soudre . Dans le cas d'un probl\u00e8me de r\u00e9gression lin\u00e9aire, aucune fonction d'activation en sortie n'est demand\u00e9e. Dans le cas d'un probl\u00e8me de classification binaire, la fonction d'activation en sortie sera la fonction logistique Attention Et dans le cas d'une classification multinomiale ? Pour une classification multinomiale, la fonction d'activation privil\u00e9gi\u00e9e en sortie du r\u00e9seau est la fonction softmax \\[ \\begin{array}{ccccc} \\mathrm{softmax} & : & \\mathbf{R}^{k} & \\to & [0,1]^{k} \\\\ & & x & \\mapsto & \\mathrm{softmax}(x) \\\\ \\end{array} \\] \\[\\mathrm{softmax}(x) := (\\frac{\\exp(x_{1})}{\\sum_{i=1}^{k}\\exp(x_{i})}, \\dots, \\frac{\\exp(x_{k})}{\\sum_{i=1}^{k}\\exp(x_{i})})\\] Remarque Dans le cas d'un probl\u00e8me de classification binaire, il est aussi possible d'utiliser en sortie la fonction softmax \u00e0 condition d'avoir modifier la cible \\(\\mathbf{y}_{i}\\) par un One-hot Encoding , ce cas l\u00e0 sera tra\u00eet\u00e9 en TP. Dans le cas des fonctions d'activations uniquement pr\u00e9sentes en sortie de couches cach\u00e9es, on a un plus grand choix possibles. Dans la pratique cependant, 2 fonctions d'activations sont plus utilis\u00e9es que les autres. La fonction d'activation devenue un standard est la fonction \\(\\mathrm{ReLU}\\) : Rectified Linear Unit, d\u00e9finie par \\[ \\begin{array}{ccccc} \\mathrm{ReLU} & : & \\mathbf{R} & \\to & \\mathbf{R} \\\\ & & x & \\mapsto & \\mathrm{ReLU}(x) \\\\ \\end{array} \\] \\[\\mathrm{ReLU}(x) := \\max(0,x)\\] Remarque La fonction \\(\\mathrm{ReLU}\\) n'est utilis\u00e9e qu'en sortie des couches cach\u00e9es, et non pas en sortie du r\u00e9seau. La fonction \\(\\mathrm{ReLU}\\) n'est pas diff\u00e9rentiable en 0, et sa d\u00e9riv\u00e9e est nulle pour \\(x<0\\) . Dans la pratique cependant, elle fonctionne tr\u00e8s bien et surtout, sa d\u00e9riv\u00e9e est tr\u00e8s rapide \u00e0 calculer. Un deuxi\u00e8me choix, aussi tr\u00e8s courant, est la fonction tangente hyperbolique, \\(\\tanh\\) . \\[ \\begin{array}{ccccc} \\tanh & : & \\mathbf{R} & \\to & [-1,1] \\\\ & & x & \\mapsto & \\frac{\\mathrm{e}^{x}-\\mathrm{e}^{-x}}{\\mathrm{e}^{x}+\\mathrm{e}^{-x}} \\\\ \\end{array} \\] Remarque Les fonctions d'activations doivent poss\u00e9der les caract\u00e9ristiques suivantes. La fonction doit \u00eatre continue et d\u00e9finie partout, La fonction doit \u00eatre monotone, La fonction ne doit pas \u00eatre lin\u00e9aire, La fonction, et ses d\u00e9riv\u00e9es, doit \u00eatre facilement calculable. Le parcours complet d'une observation \\(\\mathbf{x}_{i}\\) \u00e0 travers le DAG se nomme dans le jargon l'\u00e9tape de feedforward. Pour que cela soit plus clair, voyons celas sur un exemple. Exemple D\u00e9finissons un exemple d'\u00e9tape feedforward. On a deux entr\u00e9es \\(x_{1}, x_{2}\\) , et une sortie \\(\\hat{y}\\) . On peut donc supposer que les observations du dataset sont de la forme \\((x_{1}, x_{2}, y)\\) . Etape 1 : Les features de l'observation \\((x_{1}, x_{2})\\) sont pass\u00e9es en entr\u00e9e, chacune de ces features est envoy\u00e9e \u00e0 chaucn des neurones \\(h_{1}, h_{2}\\) de l'unique couche cach\u00e9e. Les connexions \u00e9tant pond\u00e9r\u00e9es, la r\u00e8gle des noeuds s'applique et au niveau de la couche cach\u00e9e on se retrouve avec les valeurs \\(z_{1}, z_{2}\\) d\u00e9fini\u00e9es par l'\u00e9quation \\((1)\\) , ou de fa\u00e7on \u00e9quivalente par l'\u00e9quation \\((2)\\) sous forme matricielle. La matrice \\(2 \\times 2\\) de l'\u00e9quation \\((2)\\) est la matrice de poids de la couche cach\u00e9e. Etape 2 : En sortie de la couche cach\u00e9e, la fonction d'activation \\(\\sigma^{1}\\) s'applique, on est alors \u00e0 l'\u00e9quation \\((3)\\) avec les valeurs \\((y_{1}, y_{2})\\) . Etape 3 : En arrivant au neurone de sortie, une nouvelle loi des noeuds s'applique \u00e0 l'int\u00e9rieur du neurone rouge, puis la fonction d'activation \\(\\sigma^{2}\\) . D'o\u00f9 l'\u00e9quation \\((4)\\) . Le vecteur \\(\\hat{y}\\) que l'on a en sortie de l'\u00e9tape de feedforward pour l'observation \\(x_{1}, x_{2}\\) est alors cible pr\u00e9dite (ou simplement pr\u00e9diction) par l'ANN. Comment alors mesurer l'erreur faite en pr\u00e9disant \\(\\hat{y}\\) par rapport \u00e0 la cible \\(y\\) ? Exemple Un r\u00e9seau de neurones dense avec 3 couches cach\u00e9es, 5 entr\u00e9es et 3 sorties, on peut supposer que l'on est dans le cas d'un probl\u00e8me de classification avec 3 classes distinctes.","title":"Fonction d'activation et \u00e9tape feedforward"},{"location":"test/#fonction-de-perte","text":"La fonction de perte est l\u00e0 pour calculer l'erreur obtenue entre la pr\u00e9diction et la cible. Elle est traditionnelement not\u00e9e \\(\\mathcal{L}_{\\theta}\\) . Suivant le but du r\u00e9seau de neurone on a plusieurs fonctions de pertes standards. But Fonction de pertes Activation R\u00e9gression Erreur Moyenne Absolue (MAE) aucune R\u00e9gression Erreur Moyenne Quadratique (MSE) aucune Classification Binomiale Entropie Crois\u00e9e Binomiale (BCE) sigmo\u00efde Classification Binomiale (One Hot Encoding) Entropie Crois\u00e9e Cat\u00e9gorielle (CCE) softmax Classification multinomiale Entropie Crois\u00e9e Cat\u00e9gorielle Eparse (SCCE) softmax Classification multinomiale (One Hot Encoding) Entropie Crois\u00e9e Cat\u00e9gorielle (CCE) softmax Dans le cadre des probl\u00e8mes de classification, les noms des fonctions de pertes peut \u00eatre diff\u00e9rents mais la formule est fondamentalement la m\u00eame. les modifications apport\u00e9es ne sont l\u00e0 que pour prendre en compte la forme des pr\u00e9dictions et cibles : est ce que la classe est repr\u00e9sent\u00e9e par un vecteur ou simplement par un nombre ? \\[ MAE := \\frac{1}{N}\\sum_{i=1}^{N} ||y_{i} - \\hat{y}_{i}||_{1} \\] \\[ MSE := \\frac{1}{N}\\sum_{i=1}^{N} ||y_{i} - \\hat{y}_{i}||^{2}_{2} \\] \\[ CE := -\\frac{1}{N}\\sum_{i=1}^{N} \\langle y_{i}, \\log(\\hat{y}_{i}) \\rangle \\] Le nombre \\(N\\) pr\u00e9sent dans les formules ci dessus est la taille du minibatch d'observations, pour l'instant on peut supposer que \\(N=32\\) . Sa d\u00e9finition sera claire par la suite. Remarque Dans le jargon, elle est appel\u00e9e loss function et est traditionnelement not\u00e9e \\(\\mathcal{L}_{\\theta}\\) , o\u00f9 \\(\\theta\\) repr\u00e9sente les poids et biais du r\u00e9seau. On a fait une \u00e9tape de feedforward, on a obtenu une pr\u00e9diction \\(\\hat{y}\\) dont on a calcul\u00e9e l'erreur \\(\\mathcal{L}_{\\theta}(\\hat{y})\\) gr\u00e2ce \u00e0 a fonction de perte \\(\\mathcal{L}_{\\theta}\\) . La question qui se pose maintenant est la suivante. Comment minimiser cette erreur ?","title":"Fonction de perte"},{"location":"test/#descente-du-gradient-stochastique","text":"De fa\u00e7on succinte, on utilise la methode de la technique du gradient coupl\u00e9e \u00e0 une m\u00e9thode efficace pour calculer automatiquement le gradient. Descente du gradient La m\u00e9thode de la descente du gradient est un algorithme d'optimisation permettant de trouver le minimum d'une fonction \\(f\\) . Pour simplifier l'explication, supposons que l'on consid\u00e8re la fonction d'une seule variable. \\[ \\begin{array}{ccccc} C & : & \\mathbf{R} & \\to & \\mathbf{R} \\\\ & & w & \\mapsto & C(w) \\\\ \\end{array} \\] La m\u00e9thode pour trouver un minimum de \\(C\\) est alors d'appliquer l'algorithme suivant : Initialisation Choisir un point de d\u00e9part \\(w \\in \\mathrm{dom}(C)\\) . Choisir un pas \\(\\eta\\) \"tr\u00e8s petit\". et r\u00e9p\u00e9ter : Calculer \\(C'(w)\\) Mettre \u00e0 jour \\(w := w - \\eta C'(w)\\) Si \\(w\\) est un minimum de \\(C\\) , alors \\(C'(w) = 0\\) et l'\u00e9tape 2 de la phase de r\u00e9p\u00e9tition reste bloqu\u00e9e sur \\(w\\) . Exemple de descente du gradient (mlfromscratch) La descente du gradient se g\u00e9n\u00e9ralise de la m\u00eame fa\u00e7on \u00e0 une fonction de plusieurs variables. Pour une fonction \\[f \\, : \\, \\mathbf{R}^{k} \\longrightarrow \\mathbf{R}\\] Les \u00e9tapes 2.a et 2.b ci dessus sont alors remplac\u00e9es par les \u00e9tapes suivantes. Calculer \\(\\nabla f := ( \\frac{\\partial f}{\\partial x_{1}}, \\dots, \\frac{\\partial f}{\\partial x_{k}})\\) Mettre \u00e0 jour \\(w := w - \\eta \\nabla f\\) Le but de la descente du gradient \u00e9tant de d\u00e9terminer le minimum d'une fonction, la question que l'on peut se poser de fa\u00e7on l\u00e9gitime est alorsla suivante : si l'on utilise la descente du gradient ici, quelle fonction souhaite-t-on minimiser ? Dans le cas du Deep Learning, la fonction que l'on cherche \u00e0 minimiser est la fonction de perte moyenne totale . \\[ \\mathcal{L}_{\\theta}^{\\mathrm{tot}} := \\frac{1}{n} \\sum_{i=1}^{n} \\mathcal{L}_{\\theta}(\\hat{y}_{i}) \\] On rappelle que \\(n\\) est le cardinal de \\(\\mathcal{X}\\) , ie le nombre total d'observations dans le dataset. On notera \\(\\theta\\) l'ensemble des param\u00e8tres du r\u00e9seau , on pose \\(p\\) son cardinal, (le nombre total de param\u00e8tres, poids et biais combin\u00e9) il peut aller d'une dizaine \u00e0 plusieurs milliards pour les mod\u00e8les les plus r\u00e9cents. On a donc l'ensemble suivant, \\[ \\theta := \\lbrace w_{1}, \\dots, w_{\\alpha}, b_{1}, \\dots, b_{\\beta} \\rbrace \\quad \\alpha + \\beta = p \\] Reste alors \u00e0 savoir par rapport \u00e0 quelles variables l'on souhaite calculer le gradient. Rapellons nous que dans la fonction de perte, pour une observation donn\u00e9e \\(y_{i}\\) , \\(\\hat{y}_{i}\\) est une combinaison des \u00e9l\u00e9ments de \\(y_{i}\\) et des param\u00e8tres du r\u00e9seau, la valeur de \\(y_{i}\\) \u00e9tant fixe, la seule chose qui peut varier dans la fonction de perte est la valeur des param\u00e8tres \\(\\theta\\) . Remarque Le but de l'algorithme de r\u00e9tropropagation du gradient est de trouver les param\u00e8tres \\(\\theta\\) optimaux pour minimiser la fonction de perte. Le gradient \u00e0 calculer est donc le suivant. \\[ \\nabla_{\\theta} \\mathcal{L}_{\\theta}^{\\mathrm{tot}} := \\begin{pmatrix} \\frac{\\partial \\mathcal{L}_{\\theta}^{\\mathrm{tot}}}{\\partial w_{1}} \\\\ \\frac{\\partial \\mathcal{L}_{\\theta}^{\\mathrm{tot}}}{\\partial w_{2}} \\\\ \\vdots \\\\ \\frac{\\partial \\mathcal{L}_{\\theta}^{\\mathrm{tot}}}{\\partial w_{\\alpha}} \\\\ \\frac{\\partial \\mathcal{L}_{\\theta}^{\\mathrm{tot}}}{\\partial b_{1}} \\\\ \\vdots \\\\ \\frac{\\partial \\mathcal{L}_{\\theta}^{\\mathrm{tot}}}{\\partial b_{\\beta}} \\end{pmatrix} \\] Calculer ce gradient se fait alors via l'algorithme dit d'auto-diff\u00e9rentiation inverse , c'est le choix fait par Tensorflow. Exemple : Graphe de calcul et auto-diff\u00e9rentiation inverse On prend l'exemple de la fonction suivante. \\[ f(x) := \\log(x) + \\sqrt{\\log(x)} \\] On souhaite calculer sa d\u00e9riv\u00e9, son graphe de calcul est alors le suivant. .. figure :: image_module1/autodiff_final.svg :align: center L'algorithme d'auto-diff\u00e9rentiation prend alors la forme suivante. \\[ \\begin{align} (1) \\quad \\frac{\\partial f}{\\partial f} & = 1 \\\\ (2) \\quad \\frac{\\partial f}{\\partial z} & = \\frac{\\partial f}{\\partial f} \\cdot \\frac{\\partial f}{\\partial z} =\\frac{\\partial f}{\\partial f}1 \\\\ (3) \\quad \\frac{\\partial f}{\\partial y} & = \\frac{\\partial f}{\\partial z} \\cdot \\frac{\\partial z}{\\partial y} + \\frac{\\partial f}{\\partial f}\\cdot \\frac{\\partial f}{\\partial y} = \\frac{\\partial f}{\\partial z}\\cdot \\frac{1}{2\\sqrt{y}} + \\frac{\\partial f}{\\partial f}1 \\\\ (4) \\quad \\frac{\\partial f}{\\partial x} & = \\frac{\\partial f}{\\partial y}\\cdot \\frac{\\partial y}{\\partial x} = \\frac{\\partial f}{\\partial y} \\cdot\\frac{1}{x} \\end{align} \\] Le but de la descente du gradient dans l'algorithme de r\u00e9tropropagation est alors de minimiser cette fonction de perte, et donc de minimiser l'erreur moyenne faite durant la pr\u00e9diction . Cependant pour un dataset comprenant plusieurs millions d'observations calculer le gradient complet \\(\\nabla_{\\theta}\\mathcal{L}_{\\theta}\\) est prohibitf. L'id\u00e9e est alors d'\u00e9changer ce gradient complet pour un gradient approximatif mais plus simple \u00e0 calculer . C'est le principe du minibatch. De fa\u00e7on plus d\u00e9taill\u00e9e, voici comment fonctionne l'algorithme : Algorithme de r\u00e9tropropagation L'algorithme consid\u00e8re un minibatch de taile \\(N\\) \u00e0 la fois (par exemple, avec \\(N=32\\) observations \u00e0 chaque fois), lorsque l'on parle de mini-batch de taille \\(N\\) il faut comprendre s\u00e9lection de \\(N\\) observations par un tirage sans remise . Chaque passage du dataset complet s'appelle une \u00e9poque . Durant l'\u00e9tape de feedforward, chaque passage du mini-batch dans une couche du r\u00e9seau le r\u00e9sultat obtenu est conserv\u00e9 en m\u00e9moire. Une fois le mini-batch pass\u00e9 compl\u00e8tement dans l'ANN, la pr\u00e9diction est alors \u00e9valu\u00e9e avec la fonction de perte pour en d\u00e9duire l'erreur de pr\u00e9diction faite par rapport par rapport \u00e0 la cible. L'algorithme calcule alors la contribution de chacun des poids et biais dans le calcul de l'erreur obtenue par la fonction de perte. Une descente du gradient sur la fonction de perte est alors appliqu\u00e9e pour modifier les poids et les biais, et \u00e0 terme minimiser la fonction de perte. La mise \u00e0 jour des param\u00e8tres de l'ANN se faisant suite au passage du mini-batch, la technique de descente du gradient utilis\u00e9e ici est dite descente du gradient stochastique , stochastique faisant r\u00e9f\u00e9rence ici \u00e0 la mani\u00e8re al\u00e9atoire par laquelle sont s\u00e9lectionn\u00e9es les observations composants le mini-batch. Exemple La m\u00e9thode du gradient est utilis\u00e9 pour optimiser les param\u00e8tres du r\u00e9seau de neurones. Les \u00e9tapes sont les suivantes. Comme on travaille en mini-batch de taille \\(N\\) (eg \\(N=32\\) ) on a une valeur d'erreur pour chaque pr\u00e9dictions faite sur ce mini-batch. \\[ \\mathcal{L}_{\\theta}(\\hat{y}_{1}), \\mathcal{L}_{\\theta}(\\hat{y}_{2}), \\dots, \\mathcal{L}_{\\theta}(\\hat{y}_{N}) \\] La fonction que l'on va donc utiliser pour appliquer la m\u00e9thode du gradient est la fonction de perte moyenne sur ce mini-batch. \\[ \\mathcal{L}_{\\theta} := \\frac{1}{N} \\sum_{i=1}^{N} \\mathcal{L}_{\\theta}(\\hat{y}_{i}) \\] Le gradient de cette fonction est alors d\u00e9fini par : \\[ \\nabla_{\\theta} \\mathcal{L}_{\\theta} := \\begin{pmatrix} \\frac{\\partial \\mathcal{L}_{\\theta}}{\\partial w_{1}} \\\\ \\frac{\\partial \\mathcal{L}_{\\theta}}{\\partial w_{2}} \\\\ \\vdots \\\\ \\frac{\\partial \\mathcal{L}_{\\theta}}{\\partial w_{\\alpha}} \\\\ \\frac{\\partial \\mathcal{L}_{\\theta}}{\\partial b_{1}} \\\\ \\vdots \\\\ \\frac{\\partial \\mathcal{L}_{\\theta}}{\\partial b_{\\beta}} \\end{pmatrix} \\] La mise \u00e0 jour des param\u00e8tres se fait alors via la formule suivante : \\[ w_{i} - \\eta \\frac{\\partial \\mathcal{L}_{\\theta}}{\\partial w_{i}}(\\theta) \\] \\[ b_{i} - \\eta \\frac{\\partial \\mathcal{L}_{\\theta}}{\\partial b_{i}}(\\theta) \\] \\(\\eta\\) est ici un nombre r\u00e9el que l'on appelle le taux d'apprentissage, il n'est pas appris par l'algorithme et doit \u00eatre fix\u00e9 \u00e0 la main (c'est un hyperparam\u00e8tre). Pourquoi choisir une m\u00e9thode stochastique ? Etant donn\u00e9e une fonction diff\u00e9rentiable, il est th\u00e9oriquement possible de trouver son minimum de fa\u00e7on purement analytique : une fonction \\(f : \\mathbf{R} \\rightarrow \\mathbf{R}\\) poss\u00e8de un extremum en un point \\(x\\) si sa d\u00e9riv\u00e9e \\(f'(x)\\) est nulle. Une fois trouv\u00e9 tous ces points on prend celui pour lequel \\(f(x)\\) est la plus petite valeur. Dans le cadre des r\u00e9seaux de neurones, cela revient \u00e0 devoir r\u00e9soudre \\(\\nabla \\mathcal{L}_{\\theta} = 0\\) . C'est une \u00e9quation polynomiale en \\(p\\) variables, o\u00f9 \\(p\\) est le cardinal de \\(\\theta\\) ensemble des param\u00e8tres du r\u00e9seau. Premi\u00e8rement, si cela est faisable pour \\(p=2\\) ou \\(p=3\\) , c'est difficilement r\u00e9alisable dans la pratique d'une r\u00e9seau de neurones o\u00f9 \\(p\\) d\u00e9passe facilement la centaine de milliers. Deuxi\u00e8mement, effectuer une descente du gradient classique supposerait d'avoir calcul\u00e9 les pr\u00e9dictions sur l'ensemble du dataset, et de garder en m\u00e9moire ces valeurs afin de calculer \\(\\nabla \\mathcal{L}_{\\theta}\\) . Du point de vue de la complexit\u00e9 algorithmique, le co\u00fbt de calcul de \\(\\nabla \\mathcal{L}_{\\theta}=0\\) cro\u00eet alors de fa\u00e7on lin\u00e9aire avec la taille du dataset . Dans une m\u00e9thode stochastique, la taille du mini-batch \u00e9tant fix\u00e9e (eg \\(N=32\\) ) et relativement petite par rapport \u00e0 la taille du dataset, la compl\u00e9xit\u00e9 est moindre et constante tout au long de l'algorithme. Les mises \u00e0 jour des param\u00e8tres \u00e9tant plus fr\u00e9quentes, l'algorithme converge plus rapidement vers un optimum. Remarque La descente du gradient, stochastique ou non, est \u00e0 la base une m\u00e9thode d' optimisation convexe , hors les fonctions de pertes utilis\u00e9es dans la pratique ne sont pas convexes . On se retrouve donc g\u00e9n\u00e9ralement uniquement avec des minima locaux pour la fonction de perte. Dans la pratique ce n'est pas un soucis, et de nombreuses techniques d'optimisation ont \u00e9t\u00e9 introduites pour pouvoir converger vers un minimum global au lieu de \"rester coinc\u00e9 dans un minimum local\". M\u00e9thodes que l'on verra dans les modules suivants. Sym\u00e9trie des poids La descente du gradient stochastique, n'est qu'une des m\u00e9thodes d'optimisation afin de minimiser la fonction de perte. Il existe aujourd'hui de nombreux optimiseurs pour la descente du gradient. Exemple D\u00e9finissons un exemple de l'\u00e9tape de r\u00e9tropropagation du gradient. \\[ \\begin{align} \\frac{\\partial \\mathcal{L}_{\\vartheta}}{ \\partial w_{1,1}^{1}} = & \\frac{\\partial \\mathcal{L}_{\\vartheta}}{\\partial s} \\cdot \\frac{\\partial s}{\\partial h_{1}^{2}} \\cdot \\frac{\\partial h_{1}^{2}}{\\partial h_{1}^{1}} \\cdot \\frac{\\partial h_{1}^{1}}{\\partial w_{1,1}^{1}} \\\\ + & \\frac{\\partial \\mathcal{L}_{\\vartheta}}{\\partial s} \\cdot \\frac{\\partial s}{\\partial h_{2}^{2}} \\cdot \\frac{\\partial h_{2}^{2}}{\\partial h_{1}^{1}} \\cdot \\frac{\\partial h_{1}^{1}}{\\partial w_{1,1}^{1}} \\end{align} \\] \\[ w_{1,1}^{1} \\leftarrow w_{1,1}^{1} - \\eta \\frac{\\partial \\mathcal{L}_{\\vartheta}}{ \\partial w_{1,1}^{1}}. \\] Les neurones denses sont une g\u00e9n\u00e9ralisation tr\u00e8s puissante des MLP, car ce sont des approximateurs universels . Th\u00e9or\u00e8me d'approximation universelle de Kolmogorov Toute fonction continue d\u00e9finie sur un compact \\(K \\subset \\mathbf{R}^{r}\\) peut \u00eatre uniform\u00e9ment approxim\u00e9e par un r\u00e9seau de neurones denses avec une couche cach\u00e9e.","title":"Descente du gradient stochastique"},{"location":"test/#resume","text":"Math\u00e9matiquement, un MLP peut se repr\u00e9senter par la fonction suivante. \\[ \\begin{array}{ccccc} f_{NN} & : & \\mathbf{R}^{m} & \\to & \\mathbf{R}^{k} \\\\ & & \\mathbf{x} & \\mapsto & f_{NN}(\\mathbf{x}) \\\\ \\end{array} \\] \\[ \\hat{\\mathbf{y}} := f_{NN}(\\mathbf{x}) = \\sigma^{r} \\circ \\cdots \\circ \\sigma^{1} (\\mathbf{x}) \\] L'entier \\(m\\) d\u00e9pend du nombre de features dans le dataset, l'entier \\(k\\) d\u00e9pend lui du probl\u00e8me consid\u00e9r\u00e9. Le nombre de fonctions \\(\\sigma^{i}\\) d\u00e9pend de l'architecture du r\u00e9seau et correspond au nombre de couches cach\u00e9es. \\[ \\mathbf{y}^{\\ell} := \\sigma^{\\ell}(\\mathbf{X}\\mathbf{W}_{\\ell} + \\mathbf{b}_{\\ell}) \\] O\u00f9 \\(\\mathbf{W}_{\\ell}\\) correspond \u00e0 la matrice de poids de la couche \\(\\ell\\) et \\(\\mathbf{b}_{\\ell}\\) au vecteur de biais correspondant. On a Une ligne par features dans \\(\\mathbf{X}\\) , Une colonne par neurones dans la couche cach\u00e9e, Autant de biais que de neurones dans la couche cach\u00e9e. \\[ \\begin{equation*} \\mathbf{W}_{\\ell} = \\begin{pmatrix} w_{1,1}^{\\ell} & w_{1,2}^{\\ell} & \\cdots & w_{1,r}^{\\ell} \\\\ w_{2,1}^{\\ell} & w_{2,2}^{\\ell} & \\cdots & w_{2,r}^{\\ell} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ w_{l,1}^{\\ell} & w_{l,2}^{\\ell} & \\cdots & w_{l,r}^{\\ell} \\end{pmatrix}\\end{equation*} \\in \\mathcal{M}_{l,r}(\\mathbf{R}) \\quad \\mathbf{b}_{\\ell} = \\begin{pmatrix}b_{1}^{\\ell} & b_{2}^{i} & \\cdots & b_{r}^{\\ell} \\end{pmatrix} \\] La topologie du r\u00e9seau : Le nombres de neurones, de couches, de neurones par couches, et d'arr\u00eates d\u00e9pendent du probl\u00e8me consid\u00e9r\u00e9. Il existe toutefois des architectures connues et sp\u00e9cialis\u00e9es dans certains probl\u00e8mes. Certaines couches de neurones sont ainsi sp\u00e9cialis\u00e9es dans le traitement d'images, d'autres encore dans le traitement des s\u00e9ries temporelles. Exemple Un r\u00e9seau de neurones dense avec 3 couches cach\u00e9es, 5 entr\u00e9es et 3 sorties, on peut supposer que l'on est dans le cas d'un probl\u00e8me de classification avec 3 classes distinctes. La premi\u00e8re couche cach\u00e9e a pour matrice de poids une matrice de taille \\(5\\times 10\\) , \\(\\mathbf{W}_{1} \\in \\mathcal{M}_{5,10}(\\mathbf{R})\\) , La deuxi\u00e8me couche cach\u00e9e a pour matrice de poids une matrice de taille \\(10\\times 10\\) , \\(\\mathbf{W}_{2} \\in \\mathcal{M}_{10,10}(\\mathbf{R})\\) , La trois\u00e8me couche cach\u00e9e a pour matrice de poids une matrice de taille \\(10\\times 10\\) , \\(\\mathbf{W}_{3} \\in \\mathcal{M}_{10,10}(\\mathbf{R})\\) , La couche de sortie a pour matrice de poids une matrice de taille \\(10\\times 3\\) , \\(\\mathbf{W}_{4} \\in \\mathcal{M}_{10,3}(\\mathbf{R})\\) . Concernant les biais on a des vecteurs : \\(\\mathbf{b}_{1} \\in \\mathbf{R}^{10}\\) pour la premi\u00e8re couche cach\u00e9e, \\(\\mathbf{b}_{2} \\in \\mathbf{R}^{10}\\) pour la deuxi\u00e8me couche cach\u00e9e, \\(\\mathbf{b}_{3} \\in \\mathbf{R}^{10}\\) pour la troisi\u00e8me couche cach\u00e9e, \\(\\mathbf{b}_{4} \\in \\mathbf{R}^{3}\\) pour la couche de sortie. Ce qui nous fait un nombre total de param\u00e8tres \u00e9gal \u00e0 \\(\\dim( \\mathcal{M}_{5,10}(\\mathbf{R})) + \\dim(\\mathbf{R}^{10}) + \\dim( \\mathcal{M}_{10,10}(\\mathbf{R})) + \\dim(\\mathbf{R}^{10}) +\\dim( \\mathcal{M}_{10,10}(\\mathbf{R})) + \\\\ \\dim(\\mathbf{R}^{10}) + \\dim( \\mathcal{M}_{10,3}(\\mathbf{R})) + \\dim(\\mathbf{R}^{3}) = 313\\) 313 param\u00e8tres, ce qui est loin d'\u00eatre \u00e9norme. En python, avec tensorflow, un tel r\u00e9seau ce code de la mani\u00e8re suivante. model = models . Sequential ([ Input ( shape = ( 5 ,), name = 'Input' ), Dense ( 10 ), Activation ( 'relu' ), Dense ( 10 ), Activation ( 'relu' ), Dense ( 10 ), Activation ( 'relu' ), Dense ( 3 ), Activation ( 'softmax' ) ], name = 'SeqAPI' )","title":"R\u00e9sum\u00e9"}]}